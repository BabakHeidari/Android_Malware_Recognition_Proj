{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the procedure for the 0.5 of the dataset to see whether the results are more immersive or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Specification of the directory\n",
    "directory = 'B:\\Thesis\\Codes & Data\\Main\\CCCS-CIC-Malicious-CSVs\\CCCS-CIC-Malicious-CSVs'\n",
    "\n",
    "# Use glob to match the pattern '*.csv'\n",
    "files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "\n",
    "# Now 'files' is a list of filenames\n",
    "names = []\n",
    "for file in files:\n",
    "    name = file.split(\"\\\\\")[-1].replace(\".csv\", \"\")\n",
    "    names.append(name)\n",
    "type_dict = {element: str(index+1) for index, element in enumerate(names)}\n",
    "type_dict[\"Benign\"]=\"0\"\n",
    "type_dict\n",
    "\n",
    "# # Defining the proportion of samples\n",
    "# proportion = 1\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Define the number of chunks\n",
    "n_chunks = 10\n",
    "\n",
    "# Create a directory to save the chunks\n",
    "os.makedirs('data_chunks', exist_ok=True)\n",
    "os.makedirs('data_chunks/chunk_feature_path', exist_ok=True)\n",
    "os.makedirs('data_chunks/chunk_label_path', exist_ok=True)\n",
    "\n",
    "def create_chunks(chunk_path:str, chunk_prefix:str, n_chunks:int):\n",
    "    for i in range(n_chunks):\n",
    "        pd.DataFrame([]).to_csv(path_or_buf=f\"{chunk_path}{chunk_prefix}{i}.csv\")\n",
    "\n",
    "# Function to divide data into chunks while keeping class distribution approximately equal\n",
    "# totally to 10 chunks (9 for train on ensmbels and 1 for test).\n",
    "# input: data (malware and benign types), output: 10 chunks consisting of all kinds of datasets keeping class distribution\n",
    "def bagger_in_chunks(csv_path:str, n_chunks:int, random_state:int, \n",
    "                     chunk_feature_path:str, chunk_label_path:str,\n",
    "                     target_column:\"malware\"):\n",
    "    print(\"1st bagger part started\")\n",
    "    temp_df = pd.read_csv(csv_path, header=None)\n",
    "    temp_df.columns = temp_df.columns.astype(str)\n",
    "    if target_column == \"benign\":\n",
    "        temp_df[\"target\"] = \"Benign\"\n",
    "    else:\n",
    "        temp_df[\"target\"] = name\n",
    "    temp_df = temp_df.sample(frac=1, random_state=random_state)\n",
    "    class_features = temp_df.iloc[:, 2:-1]\n",
    "    class_labels = temp_df.iloc[:, -1]\n",
    "    class_chunk_size = len(temp_df) // n_chunks\n",
    "    print(\"2nd bagger part started\")\n",
    "    for i in range(n_chunks):\n",
    "        # paths of features and labels of every chunk using their raw paths and iterator of chunks\n",
    "        final_chunk_feature_path = chunk_feature_path + f\"/chunk{i}.csv\"\n",
    "        final_chunk_label_path = chunk_label_path + f\"/chunk{i}.csv\"\n",
    "        final_chunk_features = pd.read_csv(final_chunk_feature_path)\n",
    "        final_chunk_labels = pd.read_csv(final_chunk_label_path)\n",
    "        print(f\"3rd bagger part for chunk {i} started\")\n",
    "        if i == n_chunks - 1:\n",
    "            chunk_features = class_features[i * class_chunk_size:]\n",
    "            chunk_labels = class_labels[i * class_chunk_size:]\n",
    "        else:\n",
    "            chunk_features = class_features[i * class_chunk_size:(i + 1) * class_chunk_size]\n",
    "            chunk_labels = class_labels[i * class_chunk_size:(i + 1) * class_chunk_size]\n",
    "        print(f\"4th bagger part for chunk {i} started\")\n",
    "        final_chunk_features = pd.concat([final_chunk_features, chunk_features], ignore_index=True)\n",
    "        final_chunk_labels = pd.concat([final_chunk_labels, chunk_labels], ignore_index=True)\n",
    "        final_chunk_features.to_csv(final_chunk_feature_path)\n",
    "        final_chunk_labels.to_csv(final_chunk_label_path)\n",
    "\n",
    "def duration_time_finalizer_files(file_name = str, t1=float):\n",
    "    \"\"\"finalizingthe time duration from t1 to the time dunction called\n",
    "    and showing the duration.\"\"\"\n",
    "    t2 = time.time()\n",
    "    fitting_time = t2 - t1\n",
    "    fitting_time = time.strftime(\"%H:%M:%S\", time.gmtime(fitting_time))\n",
    "    print(f\"{file_name} Runtime: {fitting_time}\")\n",
    "    return fitting_time\n",
    "        # if i >= len(chunks):\n",
    "        #     chunks.append((chunk_features, chunk_labels))\n",
    "        # else:\n",
    "        #     chunks[i] = (pd.concat([chunks[i][0], chunk_features]), pd.concat([chunks[i][1], chunk_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_chunks(chunk_path='data_chunks/chunk_feature_path/', \n",
    "              chunk_prefix='chunk', n_chunks=n_chunks)\n",
    "create_chunks(chunk_path='data_chunks/chunk_label_path/', \n",
    "              chunk_prefix='chunk', n_chunks=n_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begging of the Adwares\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Adware Runtime: 00:08:23\n",
      "begging of the Backdoors\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Backdoor Runtime: 00:07:51\n",
      "begging of the Bankers\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Banker Runtime: 00:08:04\n",
      "begging of the Droppers\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Dropper Runtime: 00:14:52\n",
      "begging of the FileInfectors\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "FileInfector Runtime: 00:14:04\n",
      "begging of the NoCategorys\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "NoCategory Runtime: 00:12:08\n",
      "begging of the PUAs\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "PUA Runtime: 00:09:27\n",
      "begging of the Ransomwares\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Ransomware Runtime: 00:09:56\n",
      "begging of the Riskwares\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Riskware Runtime: 00:28:30\n",
      "begging of the Scarewares\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Scareware Runtime: 00:26:21\n",
      "begging of the SMSs\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "SMS Runtime: 00:26:50\n",
      "begging of the Spys\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Spy Runtime: 00:28:08\n",
      "begging of the Trojans\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Trojan Runtime: 00:33:20\n",
      "begging of the Zerodays\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Zeroday Runtime: 00:59:22\n"
     ]
    }
   ],
   "source": [
    "# Loop through the files\n",
    "for file in files:\n",
    "    t1 = time.time()\n",
    "    name = file.split(\"\\\\\")[-1].replace(\".csv\", \"\")\n",
    "    print(f\"begging of the {name}s\")\n",
    "    # Read the CSV file\n",
    "    bagger_in_chunks(csv_path=file, n_chunks=n_chunks, random_state=313,\n",
    "                     chunk_feature_path='data_chunks/chunk_feature_path', \n",
    "                     chunk_label_path='data_chunks/chunk_label_path')\n",
    "    duration_time_finalizer_files(name, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begging of the Ben0s\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Ben0 Runtime: 00:48:15\n",
      "begging of the Ben1s\n",
      "1st bagger part started\n",
      "2nd bagger part started\n",
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n",
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n",
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n",
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n",
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n",
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n",
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n",
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n",
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n",
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Ben1 Runtime: 01:01:26\n",
      "begging of the Ben2s\n",
      "1st bagger part started\n",
      "2nd bagger part started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (17,18,19,20,21,22,23,24,25,26,28,29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Ben2 Runtime: 00:59:43\n",
      "begging of the Ben3s\n",
      "1st bagger part started\n",
      "2nd bagger part started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (18,19,20,21,22,23,24,25,26,27,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Ben3 Runtime: 01:30:43\n",
      "begging of the Ben4s\n",
      "1st bagger part started\n",
      "2nd bagger part started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 0 started\n",
      "4th bagger part for chunk 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 1 started\n",
      "4th bagger part for chunk 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 2 started\n",
      "4th bagger part for chunk 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 3 started\n",
      "4th bagger part for chunk 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 4 started\n",
      "4th bagger part for chunk 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 5 started\n",
      "4th bagger part for chunk 5 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 6 started\n",
      "4th bagger part for chunk 6 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 7 started\n",
      "4th bagger part for chunk 7 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 8 started\n",
      "4th bagger part for chunk 8 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_7296\\3720110341.py:63: DtypeWarning: Columns (19,20,21,22,23,24,25,26,27,28,30,31,32,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_chunk_labels = pd.read_csv(final_chunk_label_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd bagger part for chunk 9 started\n",
      "4th bagger part for chunk 9 started\n",
      "Ben4 Runtime: 01:48:47\n"
     ]
    }
   ],
   "source": [
    "# Specification the directory\n",
    "directory = 'B:\\Thesis\\Codes & Data\\Main\\CCCS-CIC-Benign-CSVs\\CCCS-CIC-Benign-CSVs'\n",
    "\n",
    "# Use glob to match the pattern '*.csv'\n",
    "files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "\n",
    "# Loop through the files\n",
    "for file in files:\n",
    "    t1 = time.time()\n",
    "    name = file.split(\"\\\\\")[-1].replace(\".csv\", \"\")\n",
    "    print(f\"begging of the {name}s\")\n",
    "    # Read the CSV file\n",
    "    bagger_in_chunks(csv_path=file, n_chunks=n_chunks, random_state=313,\n",
    "                     chunk_feature_path='data_chunks/chunk_feature_path', \n",
    "                     chunk_label_path='data_chunks/chunk_label_path',\n",
    "                     target_column=\"benign\")\n",
    "    duration_time_finalizer_files(name, t1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_time_finalizer(classifier_name = str, t1=float):\n",
    "    import time\n",
    "    \"\"\"finalizingthe time duration from t1 to the time dunction called\n",
    "    and showing the duration.\"\"\"\n",
    "    t2 = time.time()\n",
    "    fitting_time = t2 - t1\n",
    "    fitting_time = time.strftime(\"%H:%M:%S\", time.gmtime(fitting_time))\n",
    "    print(f\"{classifier_name} Runtime: {fitting_time}\")\n",
    "    return fitting_time\n",
    "\n",
    "def fit_method(classifier:str, X_train, y_train, n_estimators=50, random_state=42, n_jobs=5):\n",
    "    import time\n",
    "    t1 = time.time()\n",
    "    if classifier == \"Random Forest Classifier\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        clf_RFC = RandomForestClassifier(n_estimators=50, random_state=random_state, n_jobs=n_jobs)\n",
    "        clf_RFC.fit(X_train, y_train)\n",
    "        fitting_time = duration_time_finalizer(classifier, t1)\n",
    "        feature_importance = clf_RFC.feature_importances_\n",
    "    elif classifier ==\"Extra Trees Classifier\":\n",
    "        from sklearn.ensemble import ExtraTreesClassifier\n",
    "        t1 = time.time()\n",
    "        clf_ETC = ExtraTreesClassifier(n_estimators=n_estimators, random_state=random_state\n",
    "                                       , max_features=\"sqrt\", criterion=\"entropy\", n_jobs=n_jobs)\n",
    "        clf_ETC.fit(X_train, y_train)\n",
    "        fitting_time = duration_time_finalizer(classifier, t1)\n",
    "        feature_importance = clf_ETC.feature_importances_\n",
    "    \n",
    "    return(feature_importance, fitting_time)\n",
    "\n",
    "def pre_image_making(image_dimension_length, importance, chunk_iter:int):\n",
    "    argsorted = np.flip(importance.argsort()[-(image_dimension_length**2) :])\n",
    "    #impargmax: importance of arguments with maximum value\n",
    "    impargmax = importance[argsorted]\n",
    "    with open(f'data_chunks/meta_params/impvec_chunk{chunk_iter}.txt', 'w') as file:\n",
    "        file.write(str((argsorted, impargmax)))\n",
    "    return(argsorted, impargmax)\n",
    "\n",
    "def show_plot(impargmax, argsorted, Method:str, disp_param_num = 30, chunk_iter:int):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.bar(range(disp_param_num), impargmax[: disp_param_num])\n",
    "    plt.xticks(range(disp_param_num), argsorted[: disp_param_num], rotation=90)\n",
    "    plt.title(f\"Chunk#{chunk_iter} Feature Importance in {Method}: {disp_param_num} most important parameters\")\n",
    "    plt.savefig(f\"data_chunks/figures/Chunk{chunk_iter}_Feature_Importance_{Method}_{disp_param_num}_ImpParams\")\n",
    "    plt.show()\n",
    "\n",
    "def GB(classifier, X_train, y_train, X_test, y_test, random_state=42, max_depth=5):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.metrics import f1_score\n",
    "    # Initialize classifier\n",
    "    gbc = GradientBoostingClassifier(max_depth=max_depth, random_state=random_state)\n",
    "    # Train classifier using all features\n",
    "    t1 = time.time()\n",
    "    gbc.fit(X_train, y_train)\n",
    "    fitting_time = duration_time_finalizer(classifier, t1)\n",
    "    # Make predictions\n",
    "    preds = gbc.predict(X_test)\n",
    "    # Evaluate the model using the F1-score\n",
    "    f1_score_all = round(f1_score(y_test, preds, average='weighted'), 3)\n",
    "\n",
    "    return(f1_score_all, fitting_time)\n",
    "\n",
    "def image_label_make_and_save(selected_X_train, selected_y_train, classifier:str, datakind:str):\n",
    "    \"\"\"\"datakind: must be \"train\" or \"test\".\"\"\"\n",
    "    from PIL import Image\n",
    "    import time\n",
    "\n",
    "    # For each row in the train dataset, create an image\n",
    "    t1 = time.time()\n",
    "    for i in range(len(selected_X_train)):\n",
    "        # Reshape the row to form a square image\n",
    "        row = selected_X_train.iloc[i, :]\n",
    "        size = int(np.sqrt(len(row)))\n",
    "        if size*size != len(row):\n",
    "            print(f\"Row {i} does not have a perfect square number of elements and cannot be converted into an image.\")\n",
    "            continue\n",
    "        img_data = np.reshape(row, (size, size))\n",
    "        # Create the image from the data\n",
    "        img = Image.fromarray(img_data, mode=\"L\")\n",
    "        # Save the image\n",
    "        img.save(f'data_chunks/{classifier}_imgs/{datakind}_size_{size}/{datakind}_img_{i}.png')\n",
    "\n",
    "    image_train_create_save_time = duration_time_finalizer(classifier, t1)\n",
    "\n",
    "    with open(f\"data_chunks/{classifier}_imgs/{datakind}_size_{size}/{datakind}_img_labels.csv\", \"w\") as file:\n",
    "        for value in selected_y_train:\n",
    "            file.write(str(value)+ \", \")\n",
    "    \n",
    "    return(image_train_create_save_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_chunks):\n",
    "    X_train = pd.read_csv(f'data_chunks/chunk_feature_path/chunk{i}.csv')\n",
    "    y_train = pd.read_csv(f'data_chunks/chunk_label_path/chunk{i}.csv')\n",
    "\n",
    "    print(f\"ETC feature extraction for chunk{i} starts\")\n",
    "    ETC_feature_importance, ETC_fitting_time = fit_method(classifier=\"Extra Trees Classifier\",\n",
    "                                                      X_train=X_train, y_train=y_train)\n",
    "    \n",
    "    print(f\"ETC pre image-making for chunk{i} starts\")\n",
    "    argsorted_ETC, impargmax_ETC = pre_image_making(image_dimension_length=32, \n",
    "                                                    importance=ETC_feature_importance,\n",
    "                                                    chunk_iter=i)\n",
    "    \n",
    "    print(f\"feature extraction plotting for chunk{i} starts\")\n",
    "    show_plot(impargmax=impargmax_ETC, argsorted=argsorted_ETC, \n",
    "              Method=\"Extra Trees Classifier\", chunk_iter=i)\n",
    "\n",
    "    print(f\"splitting chunk{i} starts\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    selected_X_train_ETC, selected_X_test_ETC, selected_y_train_ETC, selected_y_test_ETC = train_test_split(X_train.iloc[:, argsorted_ETC], \n",
    "                                                        y_train, test_size=0.3,\n",
    "                                                        stratify=y_train, random_state=313)\n",
    "    print(selected_X_train_ETC.shape, \n",
    "        selected_X_test_ETC.shape, \n",
    "        selected_y_train_ETC.shape, \n",
    "        selected_y_test_ETC.shape)\n",
    "\n",
    "    print(f\"GB test on chunk{i} starts\")\n",
    "    if i == 1:\n",
    "        f1_score_all_ETC, fit_train_time_ETC_GB = GB(\"Extra Trees Classifier\",\n",
    "                                                    selected_X_train_ETC,\n",
    "                                                    selected_y_train_ETC,\n",
    "                                                    selected_X_test_ETC,\n",
    "                                                    selected_y_test_ETC)\n",
    "        print(f1_score_all_ETC, fit_train_time_ETC_GB)\n",
    "\n",
    "    print(f\"image creation from chunk{i} starts\")\n",
    "    image_train_create_save_time_ETC = image_label_make_and_save(selected_X_train_ETC,\n",
    "                                                                selected_y_train_ETC,\n",
    "                                                                classifier=\"ETC\", \n",
    "                                                                datakind=\"train\")\n",
    "\n",
    "    image_test_create_save_time_ETC = image_label_make_and_save(selected_X_test_ETC,\n",
    "                                                                selected_y_test_ETC,\n",
    "                                                                classifier=\"ETC\",\n",
    "                                                                datakind=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "try:\n",
    "    import joblib\n",
    "except ImportError:\n",
    "    !python -m pip install joblib\n",
    "    \n",
    "# Build the ensemble models\n",
    "\n",
    "def ml_weak_model_maker(sample_of_each_kind=1, X_train, y_train, model_prefix_saving:str):\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    # Initialize the meta-estimator\n",
    "    weak_LR = LogisticRegression()\n",
    "    weak_ABC = AdaBoostClassifier(random_state=313)\n",
    "    weak_XGB = XGBClassifier()\n",
    "    weak_RFC = RandomForestClassifier(criterion=\"entropy\")\n",
    "    weak_6NN = KNeighborsClassifier(n_neighbors=6) #n_neighbors=6: 1/3 the least class support, due to crowd voting theorem\n",
    "    weak_5NN = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    # ::::::::::I should add some unsupervised here::::::::::::::::::::::::::::::::::\n",
    "    ml_weak_models = [weak_LR, weak_ABC, weak_XGB, weak_RFC, weak_6NN, weak_5NN]\n",
    "    weak_ml_list_names = [\"weak_LR\", \"weak_ABC\", \"weak_XGB\",\n",
    "                          \"weak_RFC\", \"weak_6NN\", \"weak_6NN\"]\n",
    "    weak_6NN.fit(X_train, y_train)\n",
    "    weak_6NN.kneighbors_graph()\n",
    "    # Train the meta-estimator on the stacked dataset\n",
    "    for i, model in enumerate(ml_weak_models):\n",
    "        print(f\"fitting weak model {model} on trains:\")\n",
    "        model.fit(X_train, y_train)\n",
    "        joblib.dump(model, f\"{model_prefix_saving}_{weak_ml_list_names[i]}.sav\")\n",
    "        \n",
    "    return ml_weak_models, weak_ml_list_names\n",
    "\n",
    "ensemble_size_CNN = 3\n",
    "ensemble_models = build_ensemble(input_shape, num_classes, ensemble_size=ensemble_size_CNN)\n",
    "fitting_times = []\n",
    "\n",
    "\n",
    "# Execute and save the models\n",
    "def ensemble_execution(ensemble_models, n_CNNs: int, weak_ml_list_names:list,\n",
    "                       X_train, y_train, X_val, y_val, width:int):\n",
    "    t1 = time.time()\n",
    "    print(\"ml weak model making\")\n",
    "    ml_weak_models, weak_ml_list_names = ml_weak_model_maker(sample_of_each_kind=1,\n",
    "                                                             X_train=X_train,\n",
    "                                                             y_train=y_train)\n",
    "    for i, model in enumerate(ensemble_models):\n",
    "        if i < n_CNNs:\n",
    "            model_name = \"CNN\"\n",
    "            print(f\"the {model_name} model #{i+1} out of {ensemble_size} is fitting on trains:\")\n",
    "            history, _ = model_execute(X_train, y_train, X_val,\n",
    "                                       y_val, model, epochs=60, batch_size=128,\n",
    "                                       classifier=f\"Model_{i+1}\", width=width, \n",
    "                                       class_weights=None)\n",
    "            plot_model_history(history, f\"Model_{i+1}\", width, \"accuracy\", \n",
    "                               f\"data_chunks/MCHs/model_{i+1}_{model_name}_accuracy_{width}\")\n",
    "            fitting_times.append(duration_time_finalizer(f\"the model #{i+1}\", t1))\n",
    "        else:\n",
    "            model_name = weak_ml_list_names[i-n_CNNs]\n",
    "            model = ml_weak_models[i-n_CNNs]\n",
    "\n",
    "    return all_fitted_models\n",
    "\n",
    "def predict_models(model_list:list, X_test, y_test, saved_model_paths:str):\n",
    "    \"\"\"here the saved_model_paths refer to common path of all models that\n",
    "    should be modfied for each one in the process of model loading,\n",
    "    seperately for sklearn models and keras ones (maybe!!!!).\"\"\"\n",
    "    # load the model from disk\n",
    "    for model in model_list:\n",
    "        loaded_model = joblib.load(filename)\n",
    "        pred = loaded_model.predict(X_test, y_test)\n",
    "        #should add something here:::::\n",
    "\n",
    "for i, model in enumerate(ensemble_models):\n",
    "    t1 = time.time()\n",
    "    print(f\"the model #{i+1} out of {ensemble_size} is fitting on trains:\")\n",
    "    history, _ = model_execute(X_train_ETC, y_train_ETC, X_val_ETC, y_val_ETC, model, epochs=60, batch_size=128, classifier=f\"Model_{i+1}\", width=width, class_weights=None)\n",
    "    plot_model_history(history, f\"Model_{i+1}\", width, \"accuracy\", f\"Model50/figs/model_{i+1}_accuracy_32\")\n",
    "    fitting_times.append(duration_time_finalizer(\"the model #{i+1}\", t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Extract features and labels\n",
    "features = df.iloc[:, 2:-1]\n",
    "labels = df.iloc[:, -1]\n",
    "\n",
    "# Define the number of chunks\n",
    "n_chunks = 10\n",
    "\n",
    "# Create a directory to save the chunks\n",
    "os.makedirs('data_chunks', exist_ok=True)\n",
    "\n",
    "# Function to divide data into chunks while keeping class distribution approximately equal\n",
    "# def create_chunks(features, labels, n_chunks):\n",
    "#     chunks = []\n",
    "#     for class_label in labels.unique():\n",
    "#         class_features = features[labels == class_label]\n",
    "#         class_labels = labels[labels == class_label]\n",
    "#         class_chunk_size = len(class_features) // n_chunks\n",
    "#         for i in range(n_chunks):\n",
    "#             if i == n_chunks - 1:\n",
    "#                 chunk_features = class_features[i * class_chunk_size:]\n",
    "#                 chunk_labels = class_labels[i * class_chunk_size:]\n",
    "#             else:\n",
    "#                 chunk_features = class_features[i * class_chunk_size:(i + 1) * class_chunk_size]\n",
    "#                 chunk_labels = class_labels[i * class_chunk_size:(i + 1) * class_chunk_size]\n",
    "#             if i >= len(chunks):\n",
    "#                 chunks.append((chunk_features, chunk_labels))\n",
    "#             else:\n",
    "#                 chunks[i] = (pd.concat([chunks[i][0], chunk_features]), pd.concat([chunks[i][1], chunk_labels]))\n",
    "#     return chunks\n",
    "\n",
    "# Create chunks\n",
    "chunks = create_chunks(features, labels, n_chunks)\n",
    "\n",
    "# Save chunks to files\n",
    "for i, (chunk_features, chunk_labels) in enumerate(chunks):\n",
    "    chunk_features.to_csv(f'data_chunks/features_chunk_{i}.csv', index=False)\n",
    "    chunk_labels.to_csv(f'data_chunks/labels_chunk_{i}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scaling and Preprocessing Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scale data and save scaled chunks\n",
    "def scale_and_save_chunks(n_chunks):\n",
    "    scaler = MinMaxScaler((0, 255))\n",
    "    for i in range(n_chunks):\n",
    "        print(f\"scaling features for chunk{i} starts\")\n",
    "        chunk_features = pd.read_csv(f'data_chunks/chunk_feature_path/chunk{i}.csv')\n",
    "        chunk_features = scaler.fit_transform(chunk_features)\n",
    "        chunk_features = np.round(chunk_features).astype(int)\n",
    "        print(f\"saving scaled features of chunk{i} starts\")\n",
    "        pd.DataFrame(chunk_features).to_csv(f'data_chunks/chunk_feature_path/chunk{i}.csv', index=False)\n",
    "\n",
    "n_chunks\n",
    "# Scale and save chunks\n",
    "scale_and_save_chunks(n_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.drop([\"Unnamed: 0\"] ,axis=1, inplace=True)\n",
    "    df.head(5)\n",
    "    return(df)\n",
    "\n",
    "def scale(data):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler((0, 255))\n",
    "    data.columns = data.columns.astype(str)\n",
    "    scaled_data = scaler.fit_transform(data.iloc[:, 2:-1])\n",
    "    scaled_data = np.round(scaled_data).astype(int)\n",
    "    return(scaled_data)\n",
    "\n",
    "def max_value_writer(input_dataframe, output_csv):\n",
    "    with open(output_csv, \"w\") as file:\n",
    "        for value in input_dataframe.max(axis=0):\n",
    "            file.write(str(value)+ \", \")\n",
    "\n",
    "\n",
    "\n",
    "def duration_time_finalizer(classifier_name = str, t1=float):\n",
    "    import time\n",
    "    \"\"\"finalizingthe time duration from t1 to the time dunction called\n",
    "    and showing the duration.\"\"\"\n",
    "    t2 = time.time()\n",
    "    fitting_time = t2 - t1\n",
    "    fitting_time = time.strftime(\"%H:%M:%S\", time.gmtime(fitting_time))\n",
    "    print(f\"{classifier_name} Runtime: {fitting_time}\")\n",
    "    return fitting_time\n",
    "\n",
    "def GB(classifier, X_train, y_train, X_test, y_test, random_state=42, max_depth=5):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.metrics import f1_score\n",
    "    import time\n",
    "\n",
    "    # Initialize classifier\n",
    "    gbc = GradientBoostingClassifier(max_depth=max_depth, random_state=random_state)\n",
    "\n",
    "    # Train classifier using all features\n",
    "    t1 = time.time()\n",
    "    gbc.fit(X_train, y_train)\n",
    "    fitting_time = duration_time_finalizer(classifier, t1)\n",
    "\n",
    "    # Make predictions\n",
    "    preds = gbc.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using the F1-score\n",
    "    f1_score_all = round(f1_score(y_test, preds, average='weighted'), 3)\n",
    "\n",
    "    return(f1_score_all, fitting_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_label_make_and_save(selected_X_train, selected_y_train, classifier:str, datakind:str):\n",
    "    \"\"\"\"datakind: must be \"train\" or \"test\".\"\"\"\n",
    "    from PIL import Image\n",
    "    import time\n",
    "\n",
    "    # For each row in the train dataset, create an image\n",
    "    t1 = time.time()\n",
    "    for i in range(len(selected_X_train)):\n",
    "        # Reshape the row to form a square image\n",
    "        row = selected_X_train.iloc[i, :]\n",
    "        size = int(np.sqrt(len(row)))\n",
    "        if size*size != len(row):\n",
    "            print(f\"Row {i} does not have a perfect square number of elements and cannot be converted into an image.\")\n",
    "            continue\n",
    "        img_data = np.reshape(row, (size, size))\n",
    "        # Create the image from the data\n",
    "        img = Image.fromarray(img_data, mode=\"L\")\n",
    "        # Save the image\n",
    "        img.save(f'{classifier}_imgs/{datakind}_size_{size}/{datakind}_img_{i}.png')\n",
    "\n",
    "    image_train_create_save_time = duration_time_finalizer(classifier, t1)\n",
    "\n",
    "    with open(f\"{classifier}_imgs/{datakind}_size_{size}/{datakind}_img_labels.csv\", \"w\") as file:\n",
    "        for value in selected_y_train:\n",
    "            file.write(str(value)+ \", \")\n",
    "    \n",
    "    return(image_train_create_save_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USING CHUNKING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Function to scale data in chunks\n",
    "def scale_in_chunks(df, chunk_size=1000):\n",
    "    scaler = MinMaxScaler((0, 255))\n",
    "    scaled_chunks = []\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        end = start + chunk_size\n",
    "        chunk = df[start:end]\n",
    "        scaled_chunk = scaler.fit_transform(chunk)\n",
    "        scaled_chunks.append(scaled_chunk)\n",
    "    return np.vstack(scaled_chunks)\n",
    "\n",
    "# Load data\n",
    "# df = pd.read_csv(\"df.csv\")\n",
    "\n",
    "# Extract features\n",
    "ATDF_50_features = ATDF_50.iloc[:, 2:-1]\n",
    "\n",
    "# Scale data in chunks\n",
    "cross_size = 5\n",
    "chunk_size = len(ATDF_50)/cross_size\n",
    "scaled_data = scale_in_chunks(df_features, chunk_size=chunk_size)\n",
    "scaled_data = np.round(scaled_data).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USING DASK\n",
    "\n",
    "try:\n",
    "    import dask.dataframe as dd\n",
    "except ImportError:\n",
    "    !python -m pip install dask\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "df = dd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m atdf50_features \u001b[38;5;241m=\u001b[39m \u001b[43matdf50\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\base.py:376\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "df_features = df.iloc[:, 2:-1].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = MinMaxScaler((0, 255))\n",
    "scaled_data = scaler.fit_transform(df_features)\n",
    "print(\"fit transform completed\")\n",
    "scaled_data = np.round(scaled_data).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.7 GiB for an array with shape (9500, 178898) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m atdf50 \u001b[38;5;241m=\u001b[39m \u001b[43mdata_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43matdf50.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scale(atdf50)\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scaled_data\u001b[38;5;241m.\u001b[39mcopy())\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mdata_load\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_load\u001b[39m(path):\n\u001b[1;32m----> 2\u001b[0m     atdf50 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     atdf50\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m\"\u001b[39m] ,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     atdf50\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1765\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1763\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1765\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2091\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2089\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2091\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1750\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1750\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2217\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2215\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2217\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2220\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2242\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2235\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2238\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2240\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2241\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2244\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.7 GiB for an array with shape (9500, 178898) and data type int64"
     ]
    }
   ],
   "source": [
    "df = data_load(\"df.csv\")\n",
    "scaled_data = scale(df)\n",
    "X = pd.DataFrame(scaled_data.copy())\n",
    "df_features = df.iloc[:, 2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'atdf50_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m max_value_writer(\u001b[43matdf50_features\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matdf50_maxs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m max_value_writer(scaled_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaled_data_maxs50.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(scaled_data))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'atdf50_features' is not defined"
     ]
    }
   ],
   "source": [
    "max_value_writer(df_features, \"df_maxs.csv\")\n",
    "max_value_writer(scaled_data, \"scaled_data_maxs50.csv\")\n",
    "print(np.shape(scaled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25040, 9502)\n",
      "(10732, 9502)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9492</th>\n",
       "      <th>9493</th>\n",
       "      <th>9494</th>\n",
       "      <th>9495</th>\n",
       "      <th>9496</th>\n",
       "      <th>9497</th>\n",
       "      <th>9498</th>\n",
       "      <th>9499</th>\n",
       "      <th>9500</th>\n",
       "      <th>9501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>149</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>137</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  9492  \\\n",
       "22254     0     0     3    36    13    10    75    10     3    10  ...     0   \n",
       "33454     0     0    36    26    54    61   149    18    10    46  ...     0   \n",
       "23119     0     0    12    33     3     0    13     3     0     0  ...     0   \n",
       "4860      0     0     8    18    41    61   137    75     0    62  ...     0   \n",
       "14234     0     0     4    57    28     6    72    31     0     8  ...     0   \n",
       "\n",
       "       9493  9494  9495  9496  9497  9498  9499  9500  9501  \n",
       "22254     0     0     0     0     0     0     0     0     0  \n",
       "33454     0     0     0     0     0     0     0     0     0  \n",
       "23119     0     0     0     0     0     0     0     0     0  \n",
       "4860      0     0     0     0     0     0     0     0     0  \n",
       "14234     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 9502 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split(scaled_data, df)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m f1_score_GB_simple \u001b[38;5;241m=\u001b[39m \u001b[43mGB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[1;32mIn[11], line 55\u001b[0m, in \u001b[0;36mGB\u001b[1;34m(classifier, X_train, y_train, X_test, y_test, random_state, max_depth)\u001b[0m\n",
      "\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Train classifier using all features\u001b[39;00m\n",
      "\u001b[0;32m     54\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;32m---> 55\u001b[0m \u001b[43mgbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     56\u001b[0m fitting_time \u001b[38;5;241m=\u001b[39m duration_time_finalizer(classifier, t1)\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m   1150\u001b[0m     )\n",
      "\u001b[0;32m   1151\u001b[0m ):\n",
      "\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n",
      "\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n",
      "\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n",
      "\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n",
      "\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n",
      "\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n",
      "\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n",
      "\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n",
      "\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n",
      "\u001b[0;32m    607\u001b[0m         )\n",
      "\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n",
      "\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n",
      "\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n",
      "\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n",
      "\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n",
      "\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n",
      "\u001b[0;32m    250\u001b[0m     X,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n",
      "\u001b[0;32m    258\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m   1150\u001b[0m     )\n",
      "\u001b[0;32m   1151\u001b[0m ):\n",
      "\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n",
      "\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n",
      "\u001b[0;32m   1293\u001b[0m \n",
      "\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n",
      "\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n",
      "\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n",
      "\u001b[0;32m    434\u001b[0m         splitter,\n",
      "\u001b[0;32m    435\u001b[0m         min_samples_split,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n",
      "\u001b[0;32m    441\u001b[0m     )\n",
      "\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1_score_GB_simple = GB(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, classifier=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Runtime: 00:02:16\n",
      "Extra Trees Classifier Runtime: 00:03:38\n",
      "Random Forest Classifier Runtime: 00:02:16\n",
      "Extra Trees Classifier Runtime: 00:03:38\n"
     ]
    }
   ],
   "source": [
    "# RFC_feature_importance, RFC_fitting_time = fit_method(classifier=\"Random Forest Classifier\",\n",
    "#                                                      X_train=X_train, y_train=y_train)\n",
    "ETC_feature_importance, ETC_fitting_time = fit_method(classifier=\"Extra Trees Classifier\",\n",
    "                                                     X_train=X_train, y_train=y_train)\n",
    "\n",
    "# print(f\"Random Forest Classifier Runtime: {RFC_fitting_time}\")\n",
    "# print(f\"Extra Trees Classifier Runtime: {ETC_fitting_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAHICAYAAACGUcimAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABwDElEQVR4nO3deVwVVf8H8M+9IIsgi6AsioJbYqgoJoILLiQqpZh7GcrjUhamUpaYuSemZZobWWmbpllm5kIiWj4Kaq6pibkhbiCuKCQofH9/+GMeLtyLrDI3P+/X6770zpwzc87MmeE7586c0YiIgIiIiIhIZbSVXQAiIiIiIn0YqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRio0r+KRqPB1KlTK7sYFc7d3R1Dhw6t7GKQAZW9f4YOHQp3d3edaXfv3sXw4cPh7OwMjUaDsWPHIikpCRqNBl9++WWllJOK58svv4RGo0FSUlJlF4XosStRoJp3sOj7TJgwoUIKGB8fj6lTp+LWrVsVsvyyyNse+/fvr+yilNqSJUv4R6oIQ4cO1Wnn5ubmaNSoESZPnox79+5VdvFUo+B2yv+JiYmp7OIVcvnyZUydOhWHDx8uUb4zZ87glVdeQb169WBhYQEbGxu0bdsWCxYswD///FMxhS0ns2bNwpdffolRo0bhm2++wcsvv1zZRQIA/PTTTwgKCoKrqyvMzc1Ru3Zt9O3bF8eOHdObfsOGDWjZsiUsLCxQp04dTJkyBQ8ePHjMpS6b0rY/Y5WZmYmpU6fit99+eyzrmzVrFtavX/9Y1mXsHve+KQ3T0mSaPn06PDw8dKZ5eXmVS4EKio+Px7Rp0zB06FDY2dlVyDqeZEuWLIGjo+O/pnfun3/+galpqZq1Qebm5vj8888BALdv38bPP/+MGTNm4MyZM1i5cmW5rsuY5d9O+TVv3rwSSlO0y5cvY9q0aXB3d4e3t3ex8mzatAn9+vWDubk5QkND4eXlhezsbOzatQvjx4/H8ePHsWzZsooteDF99tlnyM3N1Zm2fft2tGnTBlOmTFGmiQj++ecfVKlS5XEXUXH06FHY29tjzJgxcHR0REpKCpYvX47WrVsjISFBp/1s2bIFISEh6NixIxYuXIijR49i5syZuHr1KpYuXVppdSipkra/l19+GQMHDoS5uXnFF64CZGZmYtq0aQCAjh07Vvj6Zs2ahb59+yIkJKTC12XsHve+KY1S/UXv3r07WrVqVd5leawyMjJgZWVV2cWoNJmZmahatWplF6PcWVhYlPsyTU1NMXjwYOX7a6+9Bn9/f3z33XeYN28enJycyn2dxqjgdipPld1ez507h4EDB6Ju3brYvn07XFxclHmvv/46Tp8+jU2bNlVa+QrSF3hevXoVTZo00Zmm0WjK9ZgpzXl18uTJhaYNHz4ctWvXxtKlSxEdHa1Mf+utt9CsWTNs3bpVuSC1sbHBrFmzMGbMGDRu3LhsFVApExMTmJiYVHYxSiw3NxfZ2dmVXQxVeNJijnKtr5TAihUrBID88ccfRabbvHmztGvXTqpWrSrW1tbSo0cPOXbsmE6aI0eOyJAhQ8TDw0PMzc3FyclJwsLC5Nq1a0qaKVOmCIBCn3Pnzsm5c+cEgKxYsaLQ+gHIlClTCi3n+PHjMmjQILGzsxNvb29l/jfffCMtW7YUCwsLsbe3lwEDBkhycnKptseQIUPEyspKzp8/L8HBwWJlZSWurq6yaNEiERH5888/pVOnTlK1alWpU6eOrFy5Uu8yf//9dxk5cqRUr15dqlWrJi+//LLcuHGjUBkWL14sTZo0ETMzM3FxcZHXXntNbt68qZMmICBAnn76adm/f7+0b99eLC0tZcyYMVK3bt1C2zYgIEBERK5fvy5vvvmmeHl5iZWVlVSrVk26desmhw8f1ln2jh07BICsWbNGZs6cKbVq1RJzc3Pp3LmznDp1qlB59+zZI927dxc7OzupWrWqNG3aVObPn6+T5sSJE9KnTx+xt7cXc3Nz8fHxkZ9//vmR+0PE8L4/deqUDBkyRGxtbcXGxkaGDh0qGRkZj1xe3v4s6K233hIAEh8fr0xLSkqSUaNGSaNGjcTCwkKqV68uffv2lXPnzunkzdvHu3btknHjxomjo6NUrVpVQkJC5OrVqzppc3NzZcaMGVKrVi2xtLSUjh07yrFjx6Ru3boyZMgQnbRnzpyRvn37ir29vVhaWoqvr69s3LhRJ03+/TV16lRxdXUVa2tr6dOnj9y6dUvu3bsnY8aMkRo1aoiVlZUMHTpU7t27V+rtVFBZ2quIyL1792Ty5MlSv359MTMzk9q1a8v48eMLlXHr1q3Stm1bsbW1FSsrK2nUqJFERkbqbIOCH33nkjyvvvqqAJDdu3c/so4iUmj/FPd4EhH55JNPpEmTJmJpaSl2dnbi4+Ojc55IT09Xjl8zMzOpUaOGBAYGyoEDB5Q0Q4YMkbp16xZZ36LOo8U5BvPa8W+//SajRo2SGjVqiJ2dnYiIZGRkyIkTJyQtLa1Y26ug3NxcsbGxkQEDBijTjh8/LgBk8eLFOmkvXbokAGTGjBlFLjOvvP/9739l9OjR4ujoKLa2tjJy5EjJysqSmzdvyssvvyx2dnZiZ2cn48ePl9zcXJ1l3L17VyIiIqR27dpiZmYmjRo1krlz5xZKV97tL6/s+c8ldevWleDgYNmxY4f4+PiIhYWFeHl5yY4dO0RE5McffxQvLy8xNzeXli1bysGDB3WWmXfMnjlzRrp27SpVq1YVFxcXmTZtWqnrDUBef/11+fbbb6VJkyZiamoqH3/8sd765p2nixMLiBT/XK5vXQXPlfnl7Y/Vq1dLZGSkODk5SdWqVeX5558vFAfs3LlT+vbtK25ubsr5Z+zYsZKZmal3254+fVq6d+8u1tbW0qtXr1Ito7SxhIjIzZs3ZcyYMcp+q1+/vsyePVtycnJERJTj39C+ESn7uaA456tHKVWP6u3bt3Ht2jWdaY6OjgCAb775BkOGDEFQUBA++OADZGZmYunSpWjXrh0OHTqk3OAfGxuLs2fPIiwsDM7OzsrPZsePH8eePXug0Wjwwgsv4O+//8Z3332Hjz/+WFlHjRo1kJaWVuJy9+vXDw0bNsSsWbMgIgCA999/H++99x769++P4cOHIy0tDQsXLkSHDh1w6NChUt1ukJOTg+7du6NDhw6YM2cOVq5cifDwcFhZWeHdd9/FSy+9hBdeeAHR0dEIDQ2Fn59foVspwsPDYWdnh6lTp+LkyZNYunQpzp8/j99++w0ajQYAMHXqVEybNg2BgYEYNWqUku6PP/7A7t27dXpVrl+/ju7du2PgwIEYPHgwnJyc0LFjR4wePRrW1tZ49913AUDpHTx79izWr1+Pfv36wcPDA6mpqfj0008REBCAv/76C66urjrlnT17NrRaLd566y3cvn0bc+bMwUsvvYS9e/cqaWJjY/Hcc8/BxcUFY8aMgbOzM06cOIGNGzdizJgxAIDjx4+jbdu2qFWrFiZMmAArKyt8//33CAkJwY8//ojevXuXeH8AQP/+/eHh4YGoqCgcPHgQn3/+OWrWrIkPPvigVMvLe6jB3t5emfbHH38gPj4eAwcORO3atZGUlISlS5eiY8eO+Ouvvwr1CI4ePRr29vaYMmUKkpKSMH/+fISHh2PNmjVKmsmTJ2PmzJno0aMHevTogYMHD6Jr166FeilSU1Ph7++PzMxMvPHGG3BwcMBXX32Fnj174ocffii03aKiomBpaYkJEybg9OnTWLhwIapUqQKtVoubN29i6tSp2LNnD7788kt4eHjo7fXSp+B5oUqVKrC1tQVQ9vaam5uLnj17YteuXRg5ciQ8PT1x9OhRfPzxx/j777+Ve9KOHz+O5557Ds2aNcP06dNhbm6O06dPY/fu3QAAT09PTJ8+HZMnT8bIkSPRvn17AIC/v7/Bev3yyy+oV69ekWmKUtzj6bPPPsMbb7yBvn37YsyYMbh37x7+/PNP7N27Fy+++CIA4NVXX8UPP/yA8PBwNGnSBNevX8euXbtw4sQJtGzZstC6PT098c0332DcuHGoXbs23nzzTQCGz6MlPQZfe+011KhRA5MnT0ZGRgYAYN++fejUqROmTJlS7Icbb926hfv37yMlJQXz589Heno6unTposw/dOgQABT6Nc/V1RW1a9dW5j/K6NGj4ezsjGnTpmHPnj1YtmwZ7OzsEB8fjzp16mDWrFnYvHkz5s6dCy8vL4SGhgJ4eJtEz549sWPHDgwbNgze3t749ddfMX78eFy6dAkff/yxsv3Ku/0Zcvr0abz44ot45ZVXMHjwYHz44Yd4/vnnER0djYkTJ+K1114D8PB479+/P06ePAmt9n+PpuTk5KBbt25o06YN5syZg5iYGOWe3+nTp5eo3nm2b9+O77//HuHh4XB0dETz5s2xdOlSjBo1Cr1798YLL7wAAGjWrBmA4sUC+T3qXP7NN99g+PDhaN26NUaOHAkAqF+//iO35fvvvw+NRoN33nkHV69exfz58xEYGIjDhw/D0tISALB27VpkZmZi1KhRcHBwwL59+7Bw4UJcvHgRa9eu1VnegwcPEBQUhHbt2uHDDz9Uzv8lWUZZYonMzEwEBATg0qVLeOWVV1CnTh3Ex8cjMjISV65cwfz581GjRo0i9015nAtKer7Sq9ghbb6oWd9HROTOnTtiZ2cnI0aM0MmXkpIitra2OtMLXj2IiHz33XcCQHbu3KlMmzt3bqErSREpVY/qoEGDdNIlJSWJiYmJvP/++zrTjx49KqampoWmG9oeBXtUAcisWbOUaTdv3hRLS0vRaDSyevVqZXpiYmKhsuYt08fHR7Kzs5Xpc+bMEQDKlczVq1fFzMxMunbtqlwdiYgsWrRIAMjy5cuVaQEBAQJAoqOjC9Xh6aefVnpR87t3757OckUebnNzc3OZPn26Mi3vatTT01OysrKU6QsWLBAAcvToURERefDggXh4eEjdunUL9aDlvyrv0qWLNG3aVKeHLDc3V/z9/aVhw4aFylmQoX3/n//8Rydd7969xcHB4ZHLy7uqTUtLk7S0NDl9+rR8+OGHotFoxMvLS6fs+tp0QkKCAJCvv/5amZa3jwMDA3Xyjxs3TkxMTOTWrVsi8r99HBwcrJNu4sSJhXoJxo4dq/QW5blz5454eHiIu7u7si/z9peXl5dO+xo0aJBoNBrp3r27Tvn9/PyUnrlHbSd954W8tlUe7fWbb74RrVarU0cRkejoaJ3ezrwenKJ68/74449H9mLluX37tgBQekSKo2CPanGPp169esnTTz9d5LJtbW3l9ddfLzJN/h7V/GUKDg4uVIaC26G4x2BeO27Xrp08ePBAZ7l57Sz/sfgoTz31lNJurK2tZdKkSTrbLO9vgb5fu5555hlp06ZNkcvPK29QUJDO8eTn5ycajUZeffVVZdqDBw+kdu3aOufG9evXCwCZOXOmznL79u0rGo1GTp8+LSLl3/7yl71gjyoK/Krz66+/CgCxtLSU8+fPK9M//fRTAaD0tor875gdPXq0Mi03N1eCg4PFzMxMKX9x6y3y8Pyr1Wrl+PHjOmnT0tIMtofixgIlOZdbWVkV2YuaX15brVWrlqSnpyvTv//+ewEgCxYsKLKsUVFRotFodLZ33radMGFCofQlXUZpY4kZM2aIlZWV/P333zrrmjBhgpiYmCjHUVH7pjzOBcU5Xz1KqYanWrx4MWJjY3U+wMMro1u3bmHQoEG4du2a8jExMYGvry927NihLCPvCgUA7t27h2vXrqFNmzYAgIMHD5amWI/06quv6nxft24dcnNz0b9/f53yOjs7o2HDhjrlLanhw4cr/7ezs8NTTz0FKysr9O/fX5n+1FNPwc7ODmfPni2Uf+TIkTo9TKNGjYKpqSk2b94MANi2bRuys7MxduxYnSvkESNGwMbGptD9cubm5ggLCyt2+c3NzZXl5uTk4Pr167C2tsZTTz2ld/+EhYXBzMxM+Z7XS5BXt0OHDuHcuXMYO3ZsoV7qvCvmGzduYPv27ejfvz/u3Lmj7I/r168jKCgIp06dwqVLl4pdh/wK7vv27dvj+vXrSE9Pf2TejIwM1KhRAzVq1ECDBg3w1ltvoW3btvj55591rvbzt+n79+/j+vXraNCgAezs7PRus5EjR+rkb9++PXJycnD+/HkA/9vHo0eP1kk3duzYQsvavHkzWrdujXbt2inTrK2tMXLkSCQlJeGvv/7SSR8aGqrTvnx9fSEi+M9//qOTztfXFxcuXCjWU9UWFhaFzgsfffSRTl3K0l7Xrl0LT09PNG7cWOd47dy5MwAox2te+/r5558LPVBUGnltpFq1aqVeRnGPJzs7O1y8eBF//PGHwWXZ2dlh7969uHz5cqnLY0hpjsERI0YUun+yY8eOEJESDRW3YsUKxMTEYMmSJfD09MQ///yDnJwcZX7eqAr6HiiysLAo9qgLw4YN0zme8tr+sGHDlGkmJiZo1aqVzrl58+bNMDExwRtvvKGzvDfffBMigi1btgAo//ZXlCZNmsDPz0/57uvrCwDo3Lkz6tSpU2i6vr814eHhyv81Gg3Cw8ORnZ2Nbdu2ASh+vfMEBAQUuhe6KCWNBcpyLi9KaGiozjHet29fuLi4KH9zC5Y1IyMD165dg7+/P0REb4/+qFGjCk0r6TJKG0usXbsW7du3h729vc75MjAwEDk5Odi5c2eR26O8zgXlcb4q1U//rVu31vsw1alTpwBA+cNRkI2NjfL/GzduYNq0aVi9ejWuXr2qk+727dulKdYjFfx5/dSpUxARNGzYUG/60j4Ja2FhgRo1auhMs7W1Re3atQv9jGFra4ubN28WWkbBMllbW8PFxUX5yTkvmHnqqad00pmZmaFevXrK/Dy1atXSCSQfJTc3FwsWLMCSJUtw7tw5nT8YDg4OhdLnPykC//tJPK9uZ86cAVD06BCnT5+GiOC9997De++9pzfN1atXUatWrWLXozjly98u9bGwsMAvv/wCALh48SLmzJmDq1ev6pxwgId/SKOiorBixQpcunRJub0E0N+mH7XN8vZhwbZQo0YNnVsO8tLm/THKz9PTU5mff9sXXHfez/Nubm6Fpufm5uL27dt693t+JiYmCAwM1DuvPNrrqVOncOLEiULHVp6888iAAQPw+eefY/jw4ZgwYQK6dOmCF154AX379tUJkosrr33cuXOnxHnzFPd4euedd7Bt2za0bt0aDRo0QNeuXfHiiy+ibdu2Spo5c+ZgyJAhcHNzg4+PD3r06IHQ0FDUq1ev1OXLU5pjsOB5tbTyB1wDBw5U2u6HH34I4H9/4LOysgrlvXfvXqHj0ZCStP385+bz58/D1dW10AVL/mMMKP/2V151AVDob41Wqy3Ubho1agQAOn9rilPvPCVtDyWNBcpyLi9KwfOsRqNBgwYNdMauTU5OxuTJk7Fhw4ZC27JgWU1NTVG7du1C6ynJMsoSS5w6dQp//vnnI8+XhpTXuaA8zlflOo5P3tXjN998A2dn58IryzdsUP/+/REfH4/x48fD29sb1tbWyM3NRbdu3Yp1FVpwJ+XJ/wegoIInstzcXGg0GmzZskXvE5XW1taPLIc+hp7ONDQ9f0BTUYp7Es8za9YsvPfee/jPf/6DGTNmoHr16tBqtRg7dqze/VMedctb7ltvvYWgoCC9aRo0aFDs5eVXlvIVDMCCgoLQuHFjvPLKK9iwYYMyffTo0VixYgXGjh0LPz8/2NraQqPRYODAgRW2zUpLjW00P33tNTc3F02bNsW8efP05sn742xpaYmdO3dix44d2LRpE2JiYrBmzRp07twZW7duLfHT0zY2NnB1dTU4rmdxFPd48vT0xMmTJ7Fx40bExMTgxx9/xJIlSzB58mRlCJn+/fujffv2+Omnn7B161bMnTsXH3zwAdatW4fu3buXuoxA6Y7Bkp5bisPe3h6dO3fGypUrlUA1b6SFK1euFArErly5gtatWxdr2SVp+6Vp9+Xd/oqixuO4pO2hpLFAZdUtJycHzz77LG7cuIF33nkHjRs3hpWVFS5duoShQ4cWKmv+X1FKu4yy7N/c3Fw8++yzePvtt/WmzbsgMaS8zgXlcb4q10A174blmjVrGuxZAR5e+cTFxWHatGk6D2nk9cjmZyggzbuKKvgigIJXd48qr4jAw8PjkTvtcTt16hQ6deqkfL979y6uXLmCHj16AADq1q0LADh58qTOlUl2djbOnTtX5PbPz9D2/eGHH9CpUyd88cUXOtNv3bqlPNRWEnlt49ixYwbLllePKlWqFLv8lcHFxQXjxo1THsbI+5nqhx9+wJAhQ5Sfu4GHPT2lfVlF3j4+deqUzj5OS0srdCVet25dnDx5stAyEhMTdZZVWcqjvdavXx9HjhxBly5dDLbbPFqtFl26dEGXLl0wb948zJo1C++++y527NiBwMDAR+Yv6LnnnsOyZcuQkJCg0/NXXCU5nqysrDBgwAAMGDAA2dnZeOGFF/D+++8jMjJSGUrKxcUFr732Gl577TVcvXoVLVu2xPvvv1/mQFVNx+A///yj08OUN97o/v37dYLSy5cv4+LFi8qDMxWlbt262LZtG+7cuaPTu6jvGCvv9ldRcnNzcfbsWZ2/f3///TcAKA8+l6Tehhiqb0ligZIozfYtuE4RwenTp5UHi44ePYq///4bX331lfKAHQDl1sfiKI9lFFf9+vVx9+7dRx7HhrZVeZ4Lynq+KtffIYKCgpQx7e7fv19oft4TpnlXAwWvgObPn18oT944XAX/2NvY2MDR0bHQfRZLliwpdnlfeOEFmJiYYNq0aYXKIiK4fv16sZdV3pYtW6azDZcuXYoHDx4oOzYwMBBmZmb45JNPdMr+xRdf4Pbt2wgODi7WeqysrPQGUiYmJoW2ydq1a0t9j2jLli3h4eGB+fPnF1pf3npq1qyJjh074tNPP8WVK1cKLaM0Iz1UlNGjR6Nq1aqYPXu2Mk3fNlu4cGGRvfxFCQwMRJUqVbBw4UKd5eo7Tnr06IF9+/YhISFBmZaRkYFly5bB3d29RPeMVYTyaK/9+/fHpUuX8NlnnxWa988//yhPmd64caPQ/LwgJ+9nY0PnFUPefvttWFlZYfjw4UhNTS00/8yZM1iwYIHB/MU9ngqec8zMzNCkSROICO7fv4+cnJxCPw/WrFkTrq6uen8SL6nyOgYzMzORmJhYaBQIffT9BJmUlIS4uDidW8yefvppNG7cGMuWLdM5ppYuXQqNRoO+ffsWq2yl1aNHD+Tk5GDRokU60z/++GNoNBrl3FwR7a8i5a+PiGDRokWoUqWKMuJCcetdlLwn3gvWtySxQEkY+rtWlK+//lrn9p4ffvgBV65cUeqnr6wiUuRxX1B5LKO4+vfvj4SEBPz666+F5t26dUt57sDQvimPc0F5na/KtUfVxsYGS5cuxcsvv4yWLVti4MCBqFGjBpKTk7Fp0ya0bdsWixYtgo2NjTLcwv3791GrVi1s3boV586dK7RMHx8fAMC7776LgQMHokqVKnj++eeVPxqzZ8/G8OHD0apVK+zcuVO5GiyO+vXrY+bMmYiMjERSUhJCQkJQrVo1nDt3Dj/99BNGjhyJt956q9y2T0lkZ2ejS5cuypAiS5YsQbt27dCzZ08AD+9TjIyMxLRp09CtWzf07NlTSffMM88Ue+B1Hx8fLF26FDNnzkSDBg1Qs2ZNdO7cGc899xymT5+OsLAw+Pv74+jRo1i5cmWp74PTarVYunQpnn/+eXh7eyMsLAwuLi5ITEzE8ePHlYNp8eLFaNeuHZo2bYoRI0agXr16SE1NRUJCAi5evIgjR46Uav3lzcHBAWFhYViyZAlOnDgBT09PPPfcc/jmm29ga2uLJk2aICEhAdu2bXvkvZ2G1KhRA2+99RaioqLw3HPPoUePHjh06BC2bNlSqBduwoQJ+O6779C9e3e88cYbqF69Or766iucO3cOP/74Y7nfG1dS5dFeX375ZXz//fd49dVXsWPHDrRt2xY5OTlITEzE999/j19//RWtWrXC9OnTsXPnTgQHB6Nu3bq4evUqlixZgtq1aysPm9WvXx92dnaIjo5GtWrVYGVlBV9fX4P319WvXx+rVq3CgAED4OnpqfNmqvj4eKxdu7bIt7sV93jq2rUrnJ2d0bZtWzg5OeHEiRNYtGgRgoODUa1aNdy6dUt5xWjz5s1hbW2Nbdu24Y8//tDpyS+L8jgGSzI8VdOmTdGlSxd4e3vD3t4ep06dwhdffIH79+/rXAgCwNy5c9GzZ0907doVAwcOxLFjx7Bo0SIMHz5cuWeyojz//PPo1KkT3n33XSQlJaF58+bYunUrfv75Z4wdO1b51agi2l9FsbCwQExMDIYMGQJfX19s2bIFmzZtwsSJE5V7G4tb76JYWlqiSZMmWLNmDRo1aoTq1avDy8sLXl5exY4FSsLHxwfbtm3DvHnz4OrqCg8PD7338OdXvXp1tGvXDmFhYUhNTcX8+fPRoEEDjBgxAgDQuHFj1K9fH2+99RYuXboEGxsb/Pjjj3qfMTGkPJZRXOPHj8eGDRvw3HPPYejQofDx8UFGRgaOHj2KH374AUlJSXB0dCxy35T1XHDnzp3yOV+VZIiA4g74v2PHDgkKChJbW1uxsLCQ+vXry9ChQ2X//v1KmosXL0rv3r3Fzs5ObG1tpV+/fnL58mW9wyTkDXiu1Wp1hujIzMyUYcOGia2trVSrVk369+8vV69eNThEkaHhQn788Udp166dWFlZiZWVlTRu3Fhef/11OXnyZIm3h6GBz/MGMS+o4JAxBQf8t7e3F2tra3nppZfk+vXrhfIvWrRIGjduLFWqVBEnJycZNWqUwQHU9UlJSZHg4GCpVq2aznBC9+7dkzfffFNcXFzE0tJS2rZtKwkJCRIQEKAzZEve0B5r167VWa6h4cN27dolzz77rFSrVk2srKykWbNmsnDhQp00Z86ckdDQUHF2dpYqVapIrVq15LnnnpMffvhBbx3yK+6+1zfciz5FDWR/5swZMTExUYZBuXnzpoSFhYmjo6NYW1tLUFCQJCYmFhqqyNBxlLct8w8hk5OTI9OmTVP2Q3EG/LezsxMLCwtp3bq1wQH/C+4vQ2V61LFTnO2UX1nba3Z2tnzwwQfy9NNPi7m5udjb24uPj49MmzZNbt++LSIicXFx0qtXL3F1dRUzMzNxdXWVQYMGFRqm5eeff1YGJdfXVvX5+++/ZcSIEeLu7i5mZmZSrVo1adu2rSxcuFBnCBd9w1MV53j69NNPpUOHDuLg4CDm5uZSv359GT9+vFK3rKwsGT9+vDRv3lw5hpo3by5LlizRKWdZhqcSKd4xWNTfg5IMTzVlyhRp1aqV2Nvbi6mpqbi6usrAgQPlzz//1Jv+p59+Em9vbzE3N5fatWvLpEmTdIZaM6SkbVxfm75z546MGzdOXF1dpUqVKtKwYcNCA99XRPsrasD/ggAUGg4obz/PnTu3UP3yD/jv5OQkU6ZMKTSUWnHqbWjdeeLj48XHx0fMzMx02kZxY4GSnMsTExOlQ4cOYmlpWWgov4Ly2up3330nkZGRUrNmTbG0tJTg4GCd4aJERP766y8JDAwUa2trcXR0lBEjRsiRI0cK7b+izodlXUZxYwmRh/stMjJSGjRoIGZmZuLo6Cj+/v7y4Ycf6hwzhvaNSNnOBcU9Xz2KRuQxPyVBRfryyy8RFhaGP/74w+hfU0tEROo0dOhQ/PDDD7h7925lF6VS/fbbb+jUqRPWrl1b4bePUOlU7u+BREREREQGMFAlIiIiIlVioEpEREREqsR7VImIiIhIldijSkRERESqVK7jqNKj5ebm4vLly6hWrZpq3k5CRERERRMR3LlzB66urpU+NvWThIHqY3b58uVC76kmIiIi43DhwgXUrl27sovxxGCg+pjlvSv5woULsLGxqeTSEBERUXGkp6fDzc1N+TtOjwcD1ccs7+d+GxsbBqpERERGhrftPV68yYKIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKgSERERkSoxUCUiIiIiVTKt7AJQ+XKfsKlE6ZNmB1dQSYiIiIjKhj2qRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiWjDlQXL14Md3d3WFhYwNfXF/v27Ssy/dq1a9G4cWNYWFigadOm2Lx5s878qVOnonHjxrCysoK9vT0CAwOxd+9enTTu7u7QaDQ6n9mzZ5d73YiIiIiedEYbqK5ZswYRERGYMmUKDh48iObNmyMoKAhXr17Vmz4+Ph6DBg3CsGHDcOjQIYSEhCAkJATHjh1T0jRq1AiLFi3C0aNHsWvXLri7u6Nr165IS0vTWdb06dNx5coV5TN69OgKrSsRERHRk0gjIlLZhSgNX19fPPPMM1i0aBEAIDc3F25ubhg9ejQmTJhQKP2AAQOQkZGBjRs3KtPatGkDb29vREdH611Heno6bG1tsW3bNnTp0gXAwx7VsWPHYuzYsaUqd94yb9++DRsbm1ItoyjuEzaVKH3S7OByLwMREdG/TUX//Sb9jLJHNTs7GwcOHEBgYKAyTavVIjAwEAkJCXrzJCQk6KQHgKCgIIPps7OzsWzZMtja2qJ58+Y682bPng0HBwe0aNECc+fOxYMHDwyWNSsrC+np6TofIiIiIno008ouQGlcu3YNOTk5cHJy0pnu5OSExMREvXlSUlL0pk9JSdGZtnHjRgwcOBCZmZlwcXFBbGwsHB0dlflvvPEGWrZsierVqyM+Ph6RkZG4cuUK5s2bp3e9UVFRmDZtWmmqSURERPREM8pAtSJ16tQJhw8fxrVr1/DZZ5+hf//+2Lt3L2rWrAkAiIiIUNI2a9YMZmZmeOWVVxAVFQVzc/NCy4uMjNTJk56eDjc3t4qvCBEREZGRM8qf/h0dHWFiYoLU1FSd6ampqXB2dtabx9nZuVjprays0KBBA7Rp0wZffPEFTE1N8cUXXxgsi6+vLx48eICkpCS9883NzWFjY6PzISIiIqJHM8pA1czMDD4+PoiLi1Om5ebmIi4uDn5+fnrz+Pn56aQHgNjYWIPp8y83KyvL4PzDhw9Dq9UqPa5EREREVD6M9qf/iIgIDBkyBK1atULr1q0xf/58ZGRkICwsDAAQGhqKWrVqISoqCgAwZswYBAQE4KOPPkJwcDBWr16N/fv3Y9myZQCAjIwMvP/+++jZsydcXFxw7do1LF68GJcuXUK/fv0APHwga+/evejUqROqVauGhIQEjBs3DoMHD4a9vX3lbAgiIiKifymjDVQHDBiAtLQ0TJ48GSkpKfD29kZMTIzywFRycjK02v91GPv7+2PVqlWYNGkSJk6ciIYNG2L9+vXw8vICAJiYmCAxMRFfffUVrl27BgcHBzzzzDP473//i6effhrAw5/xV69ejalTpyIrKwseHh4YN26czj2oRERERFQ+jHYcVWPFcVSJiIiMD8dRrRxGeY8qEREREf37MVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKgSERERkSoxUCUiIiIiVWKgSkRERESqxECViIiIiFSJgSoRERERqZJpZReA1MN9wqYSpU+aHVxBJSEiIiJijyoRERERqRQDVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqmRa2QWgfwf3CZtKlD5pdnAFlYSIiIj+LdijSkRERESqxECViIiIiFSJgSoRERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKhl1oLp48WK4u7vDwsICvr6+2LdvX5Hp165di8aNG8PCwgJNmzbF5s2bdeZPnToVjRs3hpWVFezt7REYGIi9e/fqpLlx4wZeeukl2NjYwM7ODsOGDcPdu3fLvW5ERERETzqjDVTXrFmDiIgITJkyBQcPHkTz5s0RFBSEq1ev6k0fHx+PQYMGYdiwYTh06BBCQkIQEhKCY8eOKWkaNWqERYsW4ejRo9i1axfc3d3RtWtXpKWlKWleeuklHD9+HLGxsdi4cSN27tyJkSNHVnh9iYiIiJ40GhGRyi5Eafj6+uKZZ57BokWLAAC5ublwc3PD6NGjMWHChELpBwwYgIyMDGzcuFGZ1qZNG3h7eyM6OlrvOtLT02Fra4tt27ahS5cuOHHiBJo0aYI//vgDrVq1AgDExMSgR48euHjxIlxdXQstIysrC1lZWTrLdHNzw+3bt2FjY1OmbaBPWd4QVVl5iYiI1C4vJqiov9+kn1H2qGZnZ+PAgQMIDAxUpmm1WgQGBiIhIUFvnoSEBJ30ABAUFGQwfXZ2NpYtWwZbW1s0b95cWYadnZ0SpAJAYGAgtFptoVsE8kRFRcHW1lb5uLm5laiuRERERE8qowxUr127hpycHDg5OelMd3JyQkpKit48KSkpxUq/ceNGWFtbw8LCAh9//DFiY2Ph6OioLKNmzZo66U1NTVG9enWD642MjMTt27eVz4ULF0pUVyIiIqInlWllF0BtOnXqhMOHD+PatWv47LPP0L9/f+zdu7dQgFpc5ubmMDc3L+dSEhEREf37GWWPqqOjI0xMTJCamqozPTU1Fc7OznrzODs7Fyu9lZUVGjRogDZt2uCLL76AqakpvvjiC2UZBR/WevDgAW7cuGFwvURERERUOkYZqJqZmcHHxwdxcXHKtNzcXMTFxcHPz09vHj8/P530ABAbG2swff7l5j0M5efnh1u3buHAgQPK/O3btyM3Nxe+vr6lrQ4RERER6WG0P/1HRERgyJAhaNWqFVq3bo358+cjIyMDYWFhAIDQ0FDUqlULUVFRAIAxY8YgICAAH330EYKDg7F69Wrs378fy5YtAwBkZGTg/fffR8+ePeHi4oJr165h8eLFuHTpEvr16wcA8PT0RLdu3TBixAhER0fj/v37CA8Px8CBA/U+8U9EREREpWe0geqAAQOQlpaGyZMnIyUlBd7e3oiJiVEemEpOToZW+78OY39/f6xatQqTJk3CxIkT0bBhQ6xfvx5eXl4AABMTEyQmJuKrr77CtWvX4ODggGeeeQb//e9/8fTTTyvLWblyJcLDw9GlSxdotVr06dMHn3zyyeOtPBEREdETwGjHUTVWFT0OG8dRJSIiKn8cR7VyGOU9qkRERET078dAlYiIiIhUiYEqEREREakSA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKgSERERkSoxUCUiIiIiVWKgSkRERESqxECViIiIiFSJgSoRERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEqmlV0AIvcJm0qUPml2cAWVhIiIiNSEPapEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsSn/smolXTEAICjBhARERkL9qgSERERkSoxUCUiIiIiVWKgSkRERESqxECViIiIiFSJgSoRERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJWMOlBdvHgx3N3dYWFhAV9fX+zbt6/I9GvXrkXjxo1hYWGBpk2bYvPmzcq8+/fv45133kHTpk1hZWUFV1dXhIaG4vLlyzrLcHd3h0aj0fnMnj27QupHRERE9CQz2kB1zZo1iIiIwJQpU3Dw4EE0b94cQUFBuHr1qt708fHxGDRoEIYNG4ZDhw4hJCQEISEhOHbsGAAgMzMTBw8exHvvvYeDBw9i3bp1OHnyJHr27FloWdOnT8eVK1eUz+jRoyu0rkRERERPIqN9heq8efMwYsQIhIWFAQCio6OxadMmLF++HBMmTCiUfsGCBejWrRvGjx8PAJgxYwZiY2OxaNEiREdHw9bWFrGxsTp5Fi1ahNatWyM5ORl16tRRplerVg3Ozs7FKmdWVhaysrKU7+np6SWuKxEREdGTyCh7VLOzs3HgwAEEBgYq07RaLQIDA5GQkKA3T0JCgk56AAgKCjKYHgBu374NjUYDOzs7nemzZ8+Gg4MDWrRogblz5+LBgwcGlxEVFQVbW1vl4+bmVowaEhEREZFR9qheu3YNOTk5cHJy0pnu5OSExMREvXlSUlL0pk9JSdGb/t69e3jnnXcwaNAg2NjYKNPfeOMNtGzZEtWrV0d8fDwiIyNx5coVzJs3T+9yIiMjERERoXxPT09nsEpERERUDEYZqFa0+/fvo3///hARLF26VGde/qCzWbNmMDMzwyuvvIKoqCiYm5sXWpa5ubne6URERERUNKP86d/R0REmJiZITU3VmZ6ammrw3lFnZ+dipc8LUs+fP4/Y2Fid3lR9fH198eDBAyQlJZW8IkRERERkkFH2qJqZmcHHxwdxcXEICQkBAOTm5iIuLg7h4eF68/j5+SEuLg5jx45VpsXGxsLPz0/5nheknjp1Cjt27ICDg8Mjy3L48GFotVrUrFmzTHWiyuE+YVOJ0ifNDq6gkhAREVFBRhmoAg9/gh8yZAhatWqF1q1bY/78+cjIyFBGAQgNDUWtWrUQFRUFABgzZgwCAgLw0UcfITg4GKtXr8b+/fuxbNkyAA+D1L59++LgwYPYuHEjcnJylPtXq1evDjMzMyQkJGDv3r3o1KkTqlWrhoSEBIwbNw6DBw+Gvb195WwIIiIion8pow1UBwwYgLS0NEyePBkpKSnw9vZGTEyM8sBUcnIytNr/3dng7++PVatWYdKkSZg4cSIaNmyI9evXw8vLCwBw6dIlbNiwAQDg7e2ts64dO3agY8eOMDc3x+rVqzF16lRkZWXBw8MD48aN07lvlYiIiIjKh9EGqgAQHh5u8Kf+3377rdC0fv36oV+/fnrTu7u7Q0SKXF/Lli2xZ8+eEpeTiIiIiErOqANVosrE+1uJiIgqllE+9U9ERERE/34MVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSx1ElqgQcg5WIiOjR2KNKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKgSERERkSoxUCUiIiIiVWKgSkRERESqxECViIiIiFSJgSoRERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpklEHqosXL4a7uzssLCzg6+uLffv2FZl+7dq1aNy4MSwsLNC0aVNs3rxZmXf//n288847aNq0KaysrODq6orQ0FBcvnxZZxk3btzASy+9BBsbG9jZ2WHYsGG4e/duhdSPiIiI6ElmtIHqmjVrEBERgSlTpuDgwYNo3rw5goKCcPXqVb3p4+PjMWjQIAwbNgyHDh1CSEgIQkJCcOzYMQBAZmYmDh48iPfeew8HDx7EunXrcPLkSfTs2VNnOS+99BKOHz+O2NhYbNy4ETt37sTIkSMrvL5ERERETxqjDVTnzZuHESNGICwsDE2aNEF0dDSqVq2K5cuX602/YMECdOvWDePHj4enpydmzJiBli1bYtGiRQAAW1tbxMbGon///njqqafQpk0bLFq0CAcOHEBycjIA4MSJE4iJicHnn38OX19ftGvXDgsXLsTq1asL9bwSERERUdkYZaCanZ2NAwcOIDAwUJmm1WoRGBiIhIQEvXkSEhJ00gNAUFCQwfQAcPv2bWg0GtjZ2SnLsLOzQ6tWrZQ0gYGB0Gq12Lt3r95lZGVlIT09XedDRERERI9mlIHqtWvXkJOTAycnJ53pTk5OSElJ0ZsnJSWlROnv3buHd955B4MGDYKNjY2yjJo1a+qkMzU1RfXq1Q0uJyoqCra2tsrHzc2tWHUkIiIietIZZaBa0e7fv4/+/ftDRLB06dIyLSsyMhK3b99WPhcuXCinUhIRERH9u5lWdgFKw9HRESYmJkhNTdWZnpqaCmdnZ715nJ2di5U+L0g9f/48tm/frvSm5i2j4MNaDx48wI0bNwyu19zcHObm5sWuGxERERE9ZJQ9qmZmZvDx8UFcXJwyLTc3F3FxcfDz89Obx8/PTyc9AMTGxuqkzwtST506hW3btsHBwaHQMm7duoUDBw4o07Zv347c3Fz4+vqWR9WIiIiI6P8ZZY8qAERERGDIkCFo1aoVWrdujfnz5yMjIwNhYWEAgNDQUNSqVQtRUVEAgDFjxiAgIAAfffQRgoODsXr1auzfvx/Lli0D8DBI7du3Lw4ePIiNGzciJydHue+0evXqMDMzg6enJ7p164YRI0YgOjoa9+/fR3h4OAYOHAhXV9fK2RBERERE/1JGG6gOGDAAaWlpmDx5MlJSUuDt7Y2YmBjlgank5GRotf/rMPb398eqVaswadIkTJw4EQ0bNsT69evh5eUFALh06RI2bNgAAPD29tZZ144dO9CxY0cAwMqVKxEeHo4uXbpAq9WiT58++OSTTyq+wkRERERPGKMNVAEgPDwc4eHheuf99ttvhab169cP/fr105ve3d0dIvLIdVavXh2rVq0qUTmJiIiIqOSM8h5VIiIiIvr3M+oeVaInkfuETSVKnzQ7uFzyEhERPW7sUSUiIiIiVWKgSkRERESqxECViIiIiFSJgSoRERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEV6gSUbHw9atERPS4sUeViIiIiFSJgSoRERERqRIDVSIiIiJSJd6jSkQVjve3EhFRabBHlYiIiIhUiYEqEREREakSA1UiIiIiUiXeo0pEqlbS+1sB3uNKRPRvwR5VIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiW+mYqI/tVK+mYrvtWKiEg92KNKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEpGHaguXrwY7u7usLCwgK+vL/bt21dk+rVr16Jx48awsLBA06ZNsXnzZp3569atQ9euXeHg4ACNRoPDhw8XWkbHjh2h0Wh0Pq+++mp5VouIiIiIYMSB6po1axAREYEpU6bg4MGDaN68OYKCgnD16lW96ePj4zFo0CAMGzYMhw4dQkhICEJCQnDs2DElTUZGBtq1a4cPPvigyHWPGDECV65cUT5z5swp17oRERERkRGPozpv3jyMGDECYWFhAIDo6Ghs2rQJy5cvx4QJEwqlX7BgAbp164bx48cDAGbMmIHY2FgsWrQI0dHRAICXX34ZAJCUlFTkuqtWrQpnZ+dyrA0RqRHHYCUiqlxG2aOanZ2NAwcOIDAwUJmm1WoRGBiIhIQEvXkSEhJ00gNAUFCQwfRFWblyJRwdHeHl5YXIyEhkZmYaTJuVlYX09HSdDxERERE9mlH2qF67dg05OTlwcnLSme7k5ITExES9eVJSUvSmT0lJKdG6X3zxRdStWxeurq74888/8c477+DkyZNYt26d3vRRUVGYNm1aidZBRMaPvbFERGVnlIFqZRo5cqTy/6ZNm8LFxQVdunTBmTNnUL9+/ULpIyMjERERoXxPT0+Hm5vbYykrERERkTEzykDV0dERJiYmSE1N1Zmemppq8N5RZ2fnEqUvLl9fXwDA6dOn9Qaq5ubmMDc3L9M6iIiIiJ5ERhmompmZwcfHB3FxcQgJCQEA5ObmIi4uDuHh4Xrz+Pn5IS4uDmPHjlWmxcbGws/Pr0xlyRvCysXFpUzLISLKw9sGiIgeMspAFQAiIiIwZMgQtGrVCq1bt8b8+fORkZGhjAIQGhqKWrVqISoqCgAwZswYBAQE4KOPPkJwcDBWr16N/fv3Y9myZcoyb9y4geTkZFy+fBkAcPLkSQAPe2OdnZ1x5swZrFq1Cj169ICDgwP+/PNPjBs3Dh06dECzZs0e8xYgIiIi+ncz2kB1wIABSEtLw+TJk5GSkgJvb2/ExMQoD0wlJydDq/3foAb+/v5YtWoVJk2ahIkTJ6Jhw4ZYv349vLy8lDQbNmxQAl0AGDhwIABgypQpmDp1KszMzLBt2zYlKHZzc0OfPn0wadKkx1RrIiIioieH0QaqABAeHm7wp/7ffvut0LR+/fqhX79+Bpc3dOhQDB061OB8Nzc3/P777yUtJhERERGVglGOo0pERERE/34MVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqmTUT/0TEZEuviyAiP5N2KNKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlPkxFREQAyvYgVknzFsxPRKQPA1UiIqp0HK2AiPRhoEpEREaNQS7RvxfvUSUiIiIiVWKgSkRERESqxECViIiIiFSJ96gSEdETi/e3EqkbA1UiIqJSYJBLVPH40z8RERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJX4MBUREdFjxgexiIqHPapEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKgSERERkSoxUCUiIiIiVTKt7AIQERFR8blP2FSi9EmzgyuoJEQVj4EqERHRE6IsQW5J8xbMT1QaRv3T/+LFi+Hu7g4LCwv4+vpi3759RaZfu3YtGjduDAsLCzRt2hSbN2/Wmb9u3Tp07doVDg4O0Gg0OHz4cKFl3Lt3D6+//jocHBxgbW2NPn36IDU1tTyrRUREREQw4h7VNWvWICIiAtHR0fD19cX8+fMRFBSEkydPombNmoXSx8fHY9CgQYiKisJzzz2HVatWISQkBAcPHoSXlxcAICMjA+3atUP//v0xYsQIvesdN24cNm3ahLVr18LW1hbh4eF44YUXsHv37gqtLxERkTHjLQtUGkYbqM6bNw8jRoxAWFgYACA6OhqbNm3C8uXLMWHChELpFyxYgG7dumH8+PEAgBkzZiA2NhaLFi1CdHQ0AODll18GACQlJeld5+3bt/HFF19g1apV6Ny5MwBgxYoV8PT0xJ49e9CmTZtCebKyspCVlaV8T09PL32liYiIiJ4gRvnTf3Z2Ng4cOIDAwEBlmlarRWBgIBISEvTmSUhI0EkPAEFBQQbT63PgwAHcv39fZzmNGzdGnTp1DC4nKioKtra2ysfNza3Y6yMiIiJ6khlloHrt2jXk5OTAyclJZ7qTkxNSUlL05klJSSlRekPLMDMzg52dXbGXExkZidu3byufCxcuFHt9RERERE8yo/3p31iYm5vD3Ny8sotBREREZHSMMlB1dHSEiYlJoaftU1NT4ezsrDePs7NzidIbWkZ2djZu3bql06ta0uUQERFR8fFBrCeXUf70b2ZmBh8fH8TFxSnTcnNzERcXBz8/P715/Pz8dNIDQGxsrMH0+vj4+KBKlSo6yzl58iSSk5NLtBwiIiIiejSj7FEFgIiICAwZMgStWrVC69atMX/+fGRkZCijAISGhqJWrVqIiooCAIwZMwYBAQH46KOPEBwcjNWrV2P//v1YtmyZsswbN24gOTkZly9fBvAwCAUe9qQ6OzvD1tYWw4YNQ0REBKpXrw4bGxuMHj0afn5+ep/4JyIiIqLSM9pAdcCAAUhLS8PkyZORkpICb29vxMTEKA9MJScnQ6v9X4exv78/Vq1ahUmTJmHixIlo2LAh1q9fr4yhCgAbNmxQAl0AGDhwIABgypQpmDp1KgDg448/hlarRZ8+fZCVlYWgoCAsWbLkMdSYiIiI6MlitIEqAISHhyM8PFzvvN9++63QtH79+qFfv34Glzd06FAMHTq0yHVaWFhg8eLFWLx4cUmKSkREREQlZJT3qBIRERHRvx8DVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKgSERERkSoxUCUiIiIiVWKgSkRERESqxECViIiIiFSJgSoRERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlYw6UF28eDHc3d1hYWEBX19f7Nu3r8j0a9euRePGjWFhYYGmTZti8+bNOvNFBJMnT4aLiwssLS0RGBiIU6dO6aRxd3eHRqPR+cyePbvc60ZERET0pDPaQHXNmjWIiIjAlClTcPDgQTRv3hxBQUG4evWq3vTx8fEYNGgQhg0bhkOHDiEkJAQhISE4duyYkmbOnDn45JNPEB0djb1798LKygpBQUG4d++ezrKmT5+OK1euKJ/Ro0dXaF2JiIiInkRGG6jOmzcPI0aMQFhYGJo0aYLo6GhUrVoVy5cv15t+wYIF6NatG8aPHw9PT0/MmDEDLVu2xKJFiwA87E2dP38+Jk2ahF69eqFZs2b4+uuvcfnyZaxfv15nWdWqVYOzs7PysbKyqujqEhERET1xjDJQzc7OxoEDBxAYGKhM02q1CAwMREJCgt48CQkJOukBICgoSEl/7tw5pKSk6KSxtbWFr69voWXOnj0bDg4OaNGiBebOnYsHDx4YLGtWVhbS09N1PkRERET0aKaVXYDSuHbtGnJycuDk5KQz3cnJCYmJiXrzpKSk6E2fkpKizM+bZigNALzxxhto2bIlqlevjvj4eERGRuLKlSuYN2+e3vVGRUVh2rRpJasgERERERlnoFqZIiIilP83a9YMZmZmeOWVVxAVFQVzc/NC6SMjI3XypKenw83N7bGUlYiIiMiYGeVP/46OjjAxMUFqaqrO9NTUVDg7O+vN4+zsXGT6vH9LskwA8PX1xYMHD5CUlKR3vrm5OWxsbHQ+RERERPRoRhmompmZwcfHB3Fxccq03NxcxMXFwc/PT28ePz8/nfQAEBsbq6T38PCAs7OzTpr09HTs3bvX4DIB4PDhw9BqtahZs2ZZqkREREREBRjtT/8REREYMmQIWrVqhdatW2P+/PnIyMhAWFgYACA0NBS1atVCVFQUAGDMmDEICAjARx99hODgYKxevRr79+/HsmXLAAAajQZjx47FzJkz0bBhQ3h4eOC9996Dq6srQkJCADx8IGvv3r3o1KkTqlWrhoSEBIwbNw6DBw+Gvb19pWwHIiIion8row1UBwwYgLS0NEyePBkpKSnw9vZGTEyM8jBUcnIytNr/dRj7+/tj1apVmDRpEiZOnIiGDRti/fr18PLyUtK8/fbbyMjIwMiRI3Hr1i20a9cOMTExsLCwAPDwZ/zVq1dj6tSpyMrKgoeHB8aNG6dzDyoRERERlQ+jDVQBIDw8HOHh4Xrn/fbbb4Wm9evXD/369TO4PI1Gg+nTp2P69Ol657ds2RJ79uwpVVmJiIiIqGSM8h5VIiIiIvr3Y6BKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREakSA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKgSERERkSoxUCUiIiIiVWKgSkRERESqxECViIiIiFSJgSoRERERqRIDVSIiIiJSJQaqRERERKRKDFSJiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlIlBqpEREREpEoMVImIiIhIlRioEhEREZEqMVAlIiIiIlVioEpEREREqsRAlYiIiIhUiYEqEREREamSUQeqixcvhru7OywsLODr64t9+/YVmX7t2rVo3LgxLCws0LRpU2zevFlnvohg8uTJcHFxgaWlJQIDA3Hq1CmdNDdu3MBLL70EGxsb2NnZYdiwYbh79265142IiIjoSWe0geqaNWsQERGBKVOm4ODBg2jevDmCgoJw9epVvenj4+MxaNAgDBs2DIcOHUJISAhCQkJw7NgxJc2cOXPwySefIDo6Gnv37oWVlRWCgoJw7949Jc1LL72E48ePIzY2Fhs3bsTOnTsxcuTICq8vERER0ZPGaAPVefPmYcSIEQgLC0OTJk0QHR2NqlWrYvny5XrTL1iwAN26dcP48ePh6emJGTNmoGXLlli0aBGAh72p8+fPx6RJk9CrVy80a9YMX3/9NS5fvoz169cDAE6cOIGYmBh8/vnn8PX1Rbt27bBw4UKsXr0aly9fflxVJyIiInoimFZ2AUojOzsbBw4cQGRkpDJNq9UiMDAQCQkJevMkJCQgIiJCZ1pQUJAShJ47dw4pKSkIDAxU5tva2sLX1xcJCQkYOHAgEhISYGdnh1atWilpAgMDodVqsXfvXvTu3bvQerOyspCVlaV8v337NgAgPT295BUvhtyszBKlz1+OJyFvZa6beR9P3spcN/OWjDGWm3lLRg3lLi95yxSRcl82FUGM0KVLlwSAxMfH60wfP368tG7dWm+eKlWqyKpVq3SmLV68WGrWrCkiIrt37xYAcvnyZZ00/fr1k/79+4uIyPvvvy+NGjUqtOwaNWrIkiVL9K53ypQpAoAffvjhhx9++PkXfC5cuFC8YIXKhVH2qBqTyMhInZ7c3Nxc3LhxAw4ODtBoNI+lDOnp6XBzc8OFCxdgY2PDvCpdN/OWjDGWm3lLxhjL/aTlrcx1l7XcJSUiuHPnDlxdXSt8XfQ/RhmoOjo6wsTEBKmpqTrTU1NT4ezsrDePs7Nzkenz/k1NTYWLi4tOGm9vbyVNwYe1Hjx4gBs3bhhcr7m5OczNzXWm2dnZFV3BCmJjY1Pqg/lJy1uZ62Ze41g38z6evJW5buY1jnWXtdwlYWtr+1jWQ/9jlA9TmZmZwcfHB3Fxccq03NxcxMXFwc/PT28ePz8/nfQAEBsbq6T38PCAs7OzTpr09HTs3btXSePn54dbt27hwIEDSprt27cjNzcXvr6+5VY/IiIiIjLSHlUAiIiIwJAhQ9CqVSu0bt0a8+fPR0ZGBsLCwgAAoaGhqFWrFqKiogAAY8aMQUBAAD766CMEBwdj9erV2L9/P5YtWwYA0Gg0GDt2LGbOnImGDRvCw8MD7733HlxdXRESEgIA8PT0RLdu3TBixAhER0fj/v37CA8Px8CBA/lTABEREVE5M9pAdcCAAUhLS8PkyZORkpICb29vxMTEwMnJCQCQnJwMrfZ/Hcb+/v5YtWoVJk2ahIkTJ6Jhw4ZYv349vLy8lDRvv/02MjIyMHLkSNy6dQvt2rVDTEwMLCwslDQrV65EeHg4unTpAq1Wiz59+uCTTz55fBUvBXNzc0yZMqXQLQjMq651M69xrJt5H0/eylw38xrHustabjIOGhGOs0BERERE6mOU96gSERER0b8fA1UiIiIiUiUGqkRERESkSgxUiYiIiEiVGKjSI/F5OyIiIqoMDFTpkczNzXHixInKLgYRERE9YYx2HFUy7J9//sGBAwdQvXp1NGnSRGfevXv38P333yM0NLRQvoiICL3Ly8nJwezZs+Hg4AAAmDdvXqE0o0ePRv/+/dG+fftSlfnEiRPYs2cP/Pz80LhxYyQmJmLBggXIysrC4MGD0blz51Itt6JkZWVBq9WiSpUqAIAzZ85g+fLlSE5ORt26dTFs2DB4eHg81jLVq1cPv/76Kxo2bPhY1peRkYHvv/8ep0+fhouLCwYNGqS0EX2uXLmCpUuXYteuXbhy5Qq0Wi3q1auHkJAQDB06FCYmJnrzffTRR+jbty/q1q1bUVWpFKmpqfj0008xefLkyi5KIdu3by+0n3r27FmhbevIkSM4cOAAOnbsiHr16uH48eNYvHgxcnNz0bt3bwQFBVXYuolIvTiO6r/M33//ja5duyI5ORkajQbt2rXD6tWr4eLiAuDhH0dXV1fk5OQUyqvVatG8eXPY2dnpTP/999/RqlUrWFlZQaPRYPv27XrzajQa1K9fH8OGDcOQIUPg7OxcrDLHxMSgV69esLa2RmZmJn766SeEhoaiefPmyM3Nxe+//46tW7eWKFg9d+6cEkDlf6lDeeXt2LEjwsPD0bdvX+zevRtdunTBU089BU9PT/z99984efIktm3bZvCVvgcPHoS9vb0SzH7zzTeIjo5WAt28N57pY+gFExEREXj77beV7f7GG28Uq763bt3C2rVrlXX369dP7/usmzRpgl27dqF69eq4cOECOnTogJs3b6JRo0Y4c+YMTE1NsWfPHr0B+v79+xEYGIgGDRrA0tISCQkJePHFF5GdnY1ff/0VTZo0QUxMDKpVq1Yor1arhVarRadOnTB8+HD07t0bZmZmxaobUP4XFffv30dSUhJq1qxZpvd+HzlyBC1bttR7LOqrA4AKH9j86tWreP7557F//35otVrk5uaiRYsWuHTpEtLS0hAREYE5c+aU+3rXrVuH/v37w87ODllZWfjpp5/Qr18/tGrVCiYmJti2bRu+/vprvPjii+W+7orQuXNnrFixosQXV8U9FvO7ffs2UlJSAADOzs6P5V30IoKkpCS4ubnB1NQU2dnZ+Omnn5CVlYUePXrA0dHRYN7s7GysX78eCQkJOuX29/dHr169SnRs55UlNzfX4IUu/QsI/auEhIRIcHCwpKWlyalTpyQ4OFg8PDzk/PnzIiKSkpIiWq1Wb96oqCjx8PCQuLg4nemmpqZy/PjxIter0Whk27ZtMmbMGHF0dJQqVapIz5495ZdffpGcnJwi8/r5+cm7774rIiLfffed2Nvby8SJE5X5EyZMkGeffdZg/lGjRsmdO3dERCQzM1P69OkjWq1WNBqNaLVa6dSpkzK/vPLa2NjI33//LSIiAQEBMm7cOJ35kyZNkrZt2xosc7NmzSQ2NlZERD777DOxtLSUN954Q5YuXSpjx44Va2tr+eKLL/Tm1Wg0Urt2bXF3d9f5aDQaqVWrlri7u4uHh4fBdffu3VvWrl0rIiLHjh0TR0dHqVGjhvj6+oqTk5M4OzvLX3/9pXe9qampIiLy0ksvib+/v9y6dUtERO7cuSOBgYEyaNAgvets27atTJ06Vfn+zTffiK+vr4iI3LhxQ7y9veWNN94wWN8VK1ZIr169pEqVKuLg4CBjxoyRo0ePGqxjfgEBAUp9d+3aJebm5tKsWTMZMGCAtGjRQqpWrSrx8fF6837wwQeSmZkpIiIPHjyQN998U8zMzESr1YqpqamEhYVJdna23rxHjhwp8rNmzRqDx6KIyNatW6V79+5iZ2cnWq1WtFqt2NnZSffu3ZW2Y8hnn30moaGhsnz5chERWb16tTRu3Fg8PDxk8uTJBvMNGDBAQkJC5Pbt23Lv3j0JDw+X0NBQERGJi4sTBwcHmT9/fpHrLsrhw4f11rlly5Yyc+ZMEXl4DrCzs5Pp06cr8z/88EPx9vYuctmbNm2SYcOGyfjx4+XEiRM6827cuCGdOnXSm8/Ly0umT58uycnJJa2O/Pzzz3o/JiYmsmjRIuW7IaU9FkUe7mNPT0+lbeR9PD095fPPPy+y3Hv37pUHDx4o33/55Rfp0KGDuLq6io+Pj3z11VcG8yYmJkrdunVFq9VKgwYN5OzZs+Lj4yNWVlZStWpVcXR0VM6NBZ06dUrq1asnFhYWEhAQIP3795f+/ftLQECAWFhYSIMGDeTUqVN6896/f1/effdd6dChg9KG58yZI1WrVhUzMzMJDQ2VrKysIutNxomB6r9MzZo15c8//1S+5+bmyquvvip16tSRM2fOFBmoiojs27dPGjVqJG+++abyB7i4gWpeEJOdnS1r1qyRoKAgMTExEVdXV5k4caLBE5CNjY0yLycnR0xNTeXgwYPK/KNHj4qTk5PBdWu1WmXdkZGRUrt2bdm+fbtkZGTIrl27pH79+jJhwoRyzWtlZaX8MXRycpLDhw/rzD99+rRYW1sbLLOlpaUkJSWJiEiLFi1k2bJlOvNXrlwpTZo00Zv3lVdeEW9v70J/wIqzn0RE7O3tlbJ3795dXnzxReUEn52dLcOGDZOuXbsWypd/H9erV0+2bt2qM3/37t3i5uamd52WlpZy5swZ5XtOTo5UqVJFUlJSRORhUObq6qo3b/71pqamygcffCCNGzcWrVYrzzzzjCxbtkzS09MN1rcsFxX528fcuXPF3t5eli9fLsePH5dvv/1WatasKR988IHBcudd9BT85L8Y0ufLL78UU1NTGThwoKxYsUI2b94smzdvlhUrVsigQYOkSpUq8vXXX+vN+/HHH4uVlZW88MIL4uLiIjNnzhQHBweZOXOmTJs2TWxsbOTTTz81uK2OHTumfL97965UqVJFbt++LSIPLzCeeuopvXmL4/Dhw6LRaApNt7KyknPnzonIw3NWlSpVdM5jZ86cKfJ4WrlypZiYmEhwcLC0a9dOLCws5Ntvv1XmF3Xe02g04uDgICYmJhIUFCQ//PCD3L9/v1j1KWof59/XhpT2WMwL0CZMmCA7duyQv/76S/766y/ZsWOHREZGipWVlcydO9fgevO36w0bNohWq5XQ0FBZvHixDB8+XExNTWXdunV68/bq1Ut69uwpf/75p4wdO1Y8PT2lV69ekp2dLffu3ZPnn39eBg8erDdvYGCg9OrVS2lP+d2+fVt69eqlt74iD49TJycniYiIkCZNmsirr74qbm5u8u2338pXX30ltWrVMngsknFjoPovU61aNb1X4K+//rrUrl1bdu7cWeSJU+Rh71hoaKg0a9ZMjh49KlWqVClRoJrf+fPnZcqUKcoVuD42NjZy+vRp5bu1tbVOUJOUlCQWFhbFWreXl5esWrVKZ/7PP/8sjRo1Kte8nTt3ljlz5oiIiL+/f6EeiB9++EHq1KljsMwODg6yf/9+EXl4caEv0LW0tDSYf926deLm5iYLFy5UphU3ULW0tFS2t4uLi85FgYjIyZMnxdbWtlA+jUYjV69eFRERV1fXQj2aRe2nunXryq5du5Tvly9fFo1Go/RWnjt3zmBeQ21r586dMmTIELGyshIrKysDtS3bRUX+dbdo0aJQgPftt9/K008/rTevg4ODfPHFF5KUlKT3s2nTJoPHRMOGDWXRokUG67R48WJp0KCB3nmNGzeWlStXiojIwYMHxdTUVKeH7fPPPxcfHx+9eWvUqKHThjIzM0Wr1cr169dF5GHAaG5ubrBcvXv3LvLTuXNnvXV2dnZWjocbN26IRqORHTt2KPP37dsnzs7OBtfr7e0tCxYsUL6vWbNGrKyslHo/KlC9dOmS/PTTT/L888+Lqamp1KhRQ958802DvZl5unXrJsHBwYXaZ0Ufi3Xq1JE1a9YYXO7q1asNXjSK6Lbrdu3aFboYf//996VNmzZ689aoUUMOHTokIg8vZDQajfz3v/9V5u/evdvguc/S0rLIX0L+/PNPg+e9evXqyS+//CIiD3tmtVqtrF69Wpm/Zs0a8fLyMrhsMl4MVP9lnnnmGYM9La+//rryM2JxfPfdd+Lk5CRarbbUgWqe3NzcQj1weZo1ayZbtmxRvh89elSnR2Pnzp1F/pSdP4BydHTU6RESeRhAGTr5lTZvfHy82NraypQpU2ThwoXi6OgokyZNkpUrV8rkyZPFzs6uyKv7wYMHy7Bhw0REpF+/fjJp0iSd+bNmzZKmTZsazC8icvHiRencubN069ZNrly5Uuw/jr6+vkoPbosWLeSnn37Smb9161a9QYFGo5GmTZtKixYtxNraWn744Qed+b///rvUqlVL7zrHjBkjXl5esmXLFtm+fbt06tRJOnbsqMyPiYmR+vXr682bv/dHn9u3bxfqkc6vLBcV+duHg4NDoT+yZ8+elapVq+rN27VrV5kxY4bBchnqXRQRMTc3l8TERIN5ExMTDQb2lpaWyq0+ecvK365PnToldnZ2evP27t1b+vTpI3fv3pXs7GwZO3asTkC8Z8+eIgNGU1NT6d69uwwdOlTvp2fPnnrPP4MHDxZfX1/59ttv5fnnn5egoCBp06aNnDhxQhITEyUgIED69u1rcL1WVlZy9uxZnWnbt28Xa2trWbp06SMD1fzt6/LlyzJr1ixp2LChaLVa8fPzM3gbjojIvHnzxM3NTQmi8rZDRR6LFhYWRQbRx48fL/JCN3+da9asqVwk5ElMTDTYRgq2L2tra52OhuTkZIMXMy4uLjrbqaANGzaIi4uL3nkWFhY6t2dYWFjo3OJx9uxZqVatmsFlk/FioPovM2vWLOnevbvB+aNGjTL4x1GfCxcuyPr16+Xu3btFpnN3d5dr164Ve7n5LV26VDZu3GhwfmRkpBLU6aPRaOSVV16RcePGSc2aNQsFxAcOHBBHR8dyzxsfHy9t2rQp9FNfrVq1Hnkf36VLl8Td3V06dOggERERYmlpKe3atZMRI0ZIhw4dxMzMTDZt2lTkMkQeXgDMmjVLnJ2dxcTEpFh/HDdu3CjVq1eXFStWyIoVK8Td3V0+//xz2b17tyxfvlzc3Nxk/PjxhfJNnTpV5xMTE6Mz/6233pKBAwfqXeedO3ekf//+YmpqKhqNRvz9/XUCi19//VW+//57vXkfdRH0KGW5qNBoNPL+++/LggULxMXFRX7//Xed+UeOHBF7e3u9edetWyfffPONwXLduHFDvvzyS73zWrZsqXcf5Hn77belZcuWeuc5ODjoBDG1a9dWbjMReRioGupBPnPmjNSvX19MTU2lSpUqYmdnp3M/7IoVKwzeRiMi0rRp0yLvjzx06JDegDElJUWeffZZsba2lqCgILl165aEh4crP503bNhQJxgqyMXFRRISEgpN/+2338Ta2lreffddg4FqURdCO3bskMGDBxfZY59XryZNmsjIkSMlIyOj2IFqaY/F9u3bS2hoqN5bFB48eCChoaHSoUMHg+vN67E+cuSI1K1bV/bt26czPzEx0WAbqV+/vk4P6pIlS3RuvTlw4IDBi5n33ntP7O3tZd68eXLkyBFJSUmRlJQUOXLkiMybN0+qV68uU6ZM0ZvXyclJ53YQf39/uXjxovL9xIkTYmNjY7DOZLwYqJLRCwgIkI4dOyqfzz77TGf+jBkzJCAgoNzz5rl69ars2bNH4uPjC/XqFOXmzZvyzjvvSJMmTcTCwkLMzMykbt268uKLL8off/xR7OWIiOzfv1/mz58vN27cKFb6H374QWrXrl3o/joLCwsZO3aszoMW5emff/4x+GBbRSrtRUXdunV1Hlj7+OOPdebPnz/f4E+kZbFjxw6xsrKSpk2byrhx42T27Nkye/ZsGTdunDRr1kysra0LBc152rZtq/OTaEG//PJLkT+RZmRkyK+//iq//PKLpKWlicjDC6LiGDp0qLz22msG5//111/i7u5erGWJPAycC/7Cok+vXr0MPiSWty2L26Oqj757KgvKzMyUV155RRo2bFjsi0aR0h2LR44cEWdnZ3FwcJDevXvLq6++Kq+++qr07t1bHBwcxMXFpcif2AveW1uwXX/33XdF3iNf8DyZX1RUlPTo0cPg/NmzZ4uLi4tShrxyuLi4FPkrVKdOnQxe2ImIfP/99wZvaSHjxuGp6F/v7NmzMDMzQ+3atSs8r5mZGY4cOQJPT88Sr+txy8nJwcGDB3H27Fnk5ubCxcUFPj4+eoeIqmylHYO1oLS0NJ36uru7l6lce/bsgbm5OVq0aFGm5eiTlJSEpUuXYs+ePTrD+Pj5+eHVV181WPbdu3fDysoK3t7eeucvWbIEubm5CA8PL3ZZituus7KykJOTg6pVqxZ72eWx3t9//x3x8fGIjIzUO3/Hjh34+uuvsWLFikLzwsLC8Mknn5Rbu9+wYQN27NiByMhI1KxZs1h5SnMs3rlzB99++63e9vHiiy/CxsbGYN7z58/rfLe2ttYZA/nrr78GAL3jbT/KuXPnYGFhoQyJWFS6/OV+1BBxf//9N6pUqWIw3apVq2Bqaor+/fuXuMykbgxU6V8h74UB/v7+eOqpp0r9woDiDmJv6OUICxYswODBg4t8OUJZlWUMVmNUljFY9cm/j11dXTFw4MAiX1RQWsa4nyqrXVfm8VRW+l5WMn/+fGRnZ6vyZSXloaJe0HLhwgVMmTIFy5cvL+cSkzFjoEpGrywvDCg4iH379u1x69atRw5iX5aXI5RV8+bN8dFHHyEwMBCff/453njjDYwYMQKenp44efIkPv/8cyxYsAD/+c9/DC7j+vXr+PPPP9G8eXNUr14d165dwxdffIGsrCz069dPVT3C7dq1w7PPPospU6YAAL799lssWrQIe/bswc2bN9G5c2d06NABCxYs0Ju/LC8qAEo/QHl57KeC7t+/r7y4oKRSU1ORlZWFOnXqGExTXu06IyMDBw4c0On9btmyJTQaTYWtNycnB+fPn4e7uzu0Wi2ysrLw888/Izc3F506dYKTk1ORZX7w4AGOHz+us4+bNGlS5PYur5eVXLx4EXZ2drC2ttaZfv/+fSQkJKBDhw7lXt+8ZeT/NWLv3r3IysqCn5+fwXpXxAta8hTnJRglbVv0L1CZ9x0QlYeyvDCgtIPYl+XlCGVVljFYRR4O9m1raysajUbs7e1l//794uHhIQ0bNpT69euLpaWlHDhwoELrUBJlGYNVpGwvKijLAOVl2U9r1qzRGbx84cKFUqdOHdFqteLg4CDTpk0zWN/09HR56aWXpE6dOsog6K+99ppyT2CHDh0M3nNZ1nadk5Mj48ePl6pVq+rcf6jRaKRu3bqyYcOGCllv3j2bWq1WvLy8JDk5Wby8vMTKykqsra3F3t5e9u7da7DM7777rtjZ2RW6h9nOzk4mTZpk8KUlZX1ZyeXLl+WZZ54RrVYrJiYm8vLLL+vcw21otIIjR46Ii4tLkfUt+IBUwfW2bdtWTExMpEOHDnLjxg0JDg5W6t2oUSO5fPlyudfZ0AsS8j4ff/yxwXuJHzx4UKq2RcaPgSoZvbK8MKAsg9iX9uUIZVXWMVgDAwNl+PDhkp6eLnPnzpXatWvL8OHDlflhYWESEhJSMYUvhbKMwSpStn1clgHKy7Kf8j+Jvnz5crGwsJDJkyfLpk2bZObMmWJlZWXwgZbw8HBp3LixfPLJJ9KxY0fp1auXeHl5ya5du+T333+XJk2a6AQWBZWlXb/zzjvi6ekpv/zyi8TGxkqHDh3kgw8+kBMnTsh7770n5ubm8uuvv5b7eoOCgqRv375y9OhRGTNmjHh6ekq/fv0kOztb7t+/L4MHD5bAwEC9ecePHy81atSQ6OhoOXfunGRmZkpmZqacO3dOPv30U6lZs6a8/fbbevOW9WUloaGh4uvrK3/88YfExsaKj4+PtGrVSnkoMiUlRe8oLWWpr4jIyy+/LP7+/rJhwwYZMGCA+Pv7S/v27eXixYty/vx5adu2rbz++uvlXueyvCChLG2LjBsDVTJ6ZXlhQFkGsRcp3csRyqqsY7Da29srwxdlZ2eLVqvV6W06cOCAwfFQK0NZxmAVKds+LssA5WXZT/mD69atWyvjwOZZsmSJtGjRQm9eNzc32b59u4g8HAZNo9HojF25cePGR75dqrTt2sXFRXbu3Kl8v3jxolhbW8u9e/dERGT69Oni5+dX7uvN36YzMzPFxMREp00fO3ZMHBwc9OZ1cnIqNNRafjExMVKzZk2988r6shJXV1edcua92cnb21uuX79usEe1LPUV0R3O6/r168orsPPExcVJvXr1yr3Orq6usn79eoPlMjR8WV6Zy9K2yHhpK/vWA6Kycnd3x6lTp5TvCQkJOvfhJScnF/kEapcuXdCyZUukp6fj5MmTOvPOnz9f5IM21tbW+OqrrxAZGYnAwMAi760qLx988AHi4uIQEBAANzc3fPTRR2jfvj1GjhyJgIAATJ06FbNnzzaYPzs7G5aWlgCAKlWqoGrVqnB0dFTmOzo64vr16xVej+KaOXMmmjRpgueffx5dunRBVlaWzsMWGo0GUVFRRS6jtPvYzs4OSUlJBpeblJRU6L7KPGXdT3n33J09exZdu3bVmde1a1ecPn1ab76rV6+iQYMGAABXV1dYWlqiUaNGynwvLy9cuHDB4HqB0rfru3fvolatWsp3FxcX3Lt3Dzdv3gQA9OnTB0eOHCn39YoITE1NAaDQvwBgYmKC3NxcvXnv3LkDV1dXg8t2cXFBRkaG3nllPffcvn0b9vb2yndzc3OsW7cO7u7u6NSpE65evao3X1nqCwA3b95U9lP16tVRtWpV1K1bV5nfoEEDXLlypdzr7OPjgwMHDhgsl0ajgRh4bKasbYuMl+mjkxCp26hRo3T+oHl5eenM37Jli8Eb+/Me0MlT8GGGX375Be3bt39kGQYOHIh27drhwIEDOif8iuDq6opDhw5h9uzZ+OWXXyAi2LdvHy5cuIC2bdti9+7daNWqlcH8bm5uOHv2rDK80erVq3X+sFy5ckUncK1s1tbWWLNmDe7du4cHDx4U2kcFg7iCyrKPhw8fjtDQULz33nvo0qWL8oBKamoq4uLiMHPmTIwePVpv3rLup5iYGNja2sLCwgKZmZk68+7du2fw4REHBwekpaXBzc0NANCrVy+dYPru3bswNzc3uN78StqumzZtiu+++w7vvvsuAOD777+HtbU1nJ2dAQC5ubnFWndJ1+vj44MPPvgA06ZNwxdffAEPDw8sWrRIuaBZuHBhofNCno4dO+Ktt97CypUrC7X7a9eu4Z133kHHjh315i3LuQcA6tWrhz///BMNGzZUppmammLt2rXo168fnnvuuXKvLwDUrFkTV65cUdpIeHg4qlevrsy/efMmrKysyr3O48ePNxj0Aw8D5B07duidV15ti4xQpfbnEtFjN3XqVPnuu+8Mzp84caK88MILj7FE6lbaAcrLouB9ezNnztSZ//nnnxv86b9bt24SHR1tcNkrVqwQf3//ci1vnm3btom5ubm0bt1aOnToIKampjqDyc+dO1c6d+5c7uvdt2+fODg4iFarlRo1asixY8fE19dXnJ2dxdXVVSwtLXV+2s4v70EkU1NTadGihXTr1k26desmLVq0EFNTU2nWrJnOqzvL09tvv23wHuf79+9Lz5499d6jWpb6ioj07NmzyBddLFq0qEL2U1lUVtuiysfhqYhIR2ZmJkxMTNg7UUBJByivSBs3bkSVKlUQFBRUaN6NGzeg1WoN3pKwZcsWWFpaGuwlLKsjR47g+++/R1ZWFoKCgvDss89WyHoKysjIQGJiIp566ilYW1vj3r17WLlyJf755x88++yzeOqppwzmzc3Nxa+//qp38PyuXbtCq62Yu+QePHiAzMxMg4PzP3jwAJcuXdLbq1yW+j7Kvn37ULVq1SJ7ZStDZbUtqlwMVIlIBwfdLj5uK6pIbF9EDFSJqIDiDLpND1X0ttq3b1+hFw34+fmhdevWReYTESQlJcHNzQ2mpqbIzs7GTz/9hKysLPTo0aPC70HOzc3V2wuZm5uLixcvFvnSAbWst3PnzlixYkWF33NelEe1r/Kqr4jgt99+U97IFxQUVOoXS1Skym7XVDn4MBXRE2bDhg1Fzj979uxjKon6Vda2unr1Kvr06YPdu3ejTp06Og9xjRs3Dm3btsWPP/6o913yJ0+eRFBQEC5cuIB69eph69at6NevHxITEyEiqFq1KuLj43Ue4Ckv6enpGD58OH755RfY2NjglVdewZQpU5S3H6WlpcHDw6PcA/uyrNfQPt65cyc2btyoPHDUs2fPci1zUevOY6h9lXU79+jRA9999x1sbW1x48YN9OjRA/v27VNG/GjUqBF27tyJGjVqlK2C5SivXScnJ6N+/fqPtV1TJauke2OJqJKUZdDtJ01lbas+ffqIn5+fJCYmFpqXmJgo/v7+0rdvX715e/XqJT179pQ///xTxo4dK56entKrVy/Jzs5WxukcPHhwuZdZROSNN96QRo0aydq1a+Wzzz6TunXrSnBwsPKWLUMD2FfmeivzeCjtusu6nfOP0ztq1Chp0qSJnD17VkRELly4ID4+PvLqq69WQI1LrzLbNVUuBqpET5iyDLr9pKmsbWVtba3ztp+C9u/fL9bW1nrn1ahRQw4dOiQiInfv3hWNRiP//e9/lfm7d++WOnXqlGt589SpU0d27NihfE9LS5PWrVtL165d5d69ewYHsK/M9Xbr1k2Cg4OVwC3P43jLXGnbV1m3c/5A9amnnpKff/5ZZ/62bdvEw8OjhLWpWJXZrqlyccB/oidMWQbdftJU1rYyNzdHenq6wfl37twxOCrD3bt3lTExraysYGVlpTNOrpubG1JTU8u3wP8vLS1N555OR0dHbNu2DXfu3EGPHj0KjQerhvVu2bIFXbp0QatWrbBx48YKKZ8hpW1f5bGd88bhvXnzJurXr68zr0GDBrh8+XJxq/FYVGa7psrFQJXoCTN+/Hj4+/sbnF/UoNtPmsraVgMGDMCQIUPw008/6QSs6enp+OmnnxAWFoZBgwbpzevq6ork5GTl+5w5c3TuZU1LS9N5G1J5qlOnDk6cOKEzrVq1ati6dSv++ecf9O7dW5XrHTduHDZs2IB33nkHr7zySoUF1AWVtn2Vx3YeOnQoXnjhBdy/fx/nzp3TmZeSkmJweLPKUpntmioXA1WiJ0z79u3RrVs3g/OtrKwQEBDwGEukXpW1rebNm4fu3btj4MCBsLe3h6WlJSwtLWFvb4+BAweie/fu+PDDD/XmDQwMRGJiovJ91KhRqFatmvJ969ataNmyZbmXGXj4lrAVK1YUmm5tbY1ff/0VFhYWql2vt7c39u/fD41GA29v78fyq0Jp21dZ6ztkyBDUrFkTtra26NWrV6HA/Mcff4S3t3fxKvGYVGa7psrF4amIiFQqPT0dBw4c0BmeysfHx+AA8cVx7tw5WFhYFPkO+tK6efMmLl++jKefflrv/Dt37uDgwYPlHtyX93o3bNiAHTt2IDIyUu/ICpWtordzRkYGTExMKuzCoiJUZLumysUeVSIiFTpx4gR+/PFHuLi4YNCgQWjRogW+//57jB07Ftu3b39k3hUrVig9UImJiRg1ahT+85//4Ny5cxX2x9ze3h5ardbguv/4448K6YEu63oLbq9GjRrhn3/+wYQJEx65rStDRW/nGzdu4LXXXiuv4pabymrXVMkq80kuIiIqbMuWLWJmZibVq1cXCwsL2bJli9SoUUMCAwOlc+fOYmJiInFxceWetzLLXVnrrcztVVoVXebDhw+rbuQPY9xPVD4YqBIRqYyfn5+8++67IiLy3Xffib29vUycOFGZP2HCBHn22WfLPW9llruy1luZ26u0ylrmn3/+ucjPxx9/rLpA1Rj3E5UPBqpERCpjY2Mjp06dEhGRnJwcMTU11RlX9ejRo+Lk5FTueSuz3JW13srcXqVV1jIb40s/jHE/UfngPapERCqUN86lVquFhYUFbG1tlXnVqlXD7du3KyRvWVXWuo11e5VWWcrs4uKCdevWITc3V+/n4MGDFV7+0jDG/URlx0CViEhl3N3dcerUKeV7QkIC6tSpo3xPTk42+OBIWfKWVWWt21i3V2mVtczG+NIPY9xPVD5MK7sARESka9SoUcjJyVG+e3l56czfsmULOnfuXO55y6qy1m2s26u0ylrm8ePHIyMjw+B8Nb70wxj3E5UPjqNKRERERKrEn/6JiIiISJUYqBIRERGRKjFQJSIiIiJVYqBKRERERKrEQJWIiIiIVImBKhERERGpEgNVIiIiIlKl/wPbR+VO3Vv0WQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# argsorted_RFC, impargmax_RFC = pre_image_making(image_dimension_length=32, importance=RFC_feature_importance)\n",
    "argsorted_ETC, impargmax_ETC = pre_image_making(image_dimension_length=32, importance=ETC_feature_importance)\n",
    "# show_plot(impargmax=impargmax_RFC, argsorted=argsorted_RFC, Method=\"Random Forest Classifier\")\n",
    "show_plot(impargmax=impargmax_ETC, argsorted=argsorted_ETC, Method=\"Extra Trees Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25040, 1024) (10732, 1024) (25040,) (10732,)\n",
      "(25040, 1024) (10732, 1024) (25040,) (10732,)\n"
     ]
    }
   ],
   "source": [
    "# selected_X_train_RFC, selected_X_test_RFC, selected_y_train_RFC, selected_y_test_RFC = split(X.iloc[:, argsorted_RFC], df)\n",
    "selected_X_train_ETC, selected_X_test_ETC, selected_y_train_ETC, selected_y_test_ETC = split(X.iloc[:, argsorted_ETC], df)\n",
    "# print(selected_X_train_RFC.shape, selected_X_test_RFC.shape, selected_y_train_RFC.shape, selected_y_test_RFC.shape)\n",
    "print(selected_X_train_ETC.shape, selected_X_test_ETC.shape, selected_y_train_ETC.shape, selected_y_test_ETC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting on Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Runtime: 00:20:50\n",
      "0.894 00:20:50\n",
      "Random Forest Classifier Runtime: 00:19:04\n",
      "0.894 00:19:04\n"
     ]
    }
   ],
   "source": [
    "# f1_score_all_RFC, fit_train_time_RFC_GB = GB(\"Random Forest Classifier\",\n",
    "#                                              selected_X_train_RFC,\n",
    "#                                              selected_y_train_RFC,\n",
    "#                                              selected_X_test_RFC,\n",
    "#                                              selected_y_test_RFC)\n",
    "# print(f1_score_all_RFC, fit_train_time_RFC_GB)\n",
    "\n",
    "f1_score_all_ETC, fit_train_time_ETC_GB = GB(\"Extra Trees Classifier\",\n",
    "                                             selected_X_train_ETC,\n",
    "                                             selected_y_train_ETC,\n",
    "                                             selected_X_test_ETC,\n",
    "                                             selected_y_test_ETC)\n",
    "print(f1_score_all_ETC, fit_train_time_ETC_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Creation and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Runtime: 00:00:43\n",
      "ETC Runtime: 00:00:45\n"
     ]
    }
   ],
   "source": [
    "# image_train_create_save_time_RFC = image_label_make_and_save(selected_X_train_RFC,\n",
    "#                                                              selected_y_train_RFC,\n",
    "#                                                              \"RFC\", datakind=\"train\")\n",
    "\n",
    "image_train_create_save_time_ETC = image_label_make_and_save(selected_X_train_ETC,\n",
    "                                                             selected_y_train_ETC,\n",
    "                                                             \"ETC50\", datakind=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Runtime: 00:00:20\n",
      "ETC Runtime: 00:00:16\n"
     ]
    }
   ],
   "source": [
    "# image_test_create_save_time_RFC = image_label_make_and_save(selected_X_test_RFC,\n",
    "#                                                              selected_y_test_RFC,\n",
    "#                                                              \"RFC\",\n",
    "#                                                              \"test\")\n",
    "\n",
    "image_test_create_save_time_ETC = image_label_make_and_save(selected_X_test_ETC,\n",
    "                                                             selected_y_test_ETC,\n",
    "                                                             \"ETC50\",\n",
    "                                                             \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.metrics import F1Score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from mlxtend.classifier import StackingClassifier as MLXTStackingClassifier\n",
    "\n",
    "def build_model(input_shape: tuple, conv_layers: list, dense_layers: list, dropout_rates: list, output_activation: str, num_classes: int):\n",
    "    model = Sequential()\n",
    "    total_layers = len(conv_layers) + len(dense_layers) + 1  # total layers + final dropout\n",
    "    if len(dropout_rates) != total_layers:\n",
    "        raise ValueError(f\"Length of dropout_rates should be {total_layers} but is {len(dropout_rates)}\")\n",
    "\n",
    "    for i, (filters, kernel_size) in enumerate(conv_layers):\n",
    "        if i == 0:\n",
    "            model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Conv2D(filters, kernel_size, activation='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "        model.add(Dropout(rate=dropout_rates[i]))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    for j, units in enumerate(dense_layers):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rates[len(conv_layers) + j]))\n",
    "\n",
    "    model.add(Dense(num_classes, activation=output_activation))\n",
    "    model.add(Dropout(rate=dropout_rates[-1]))  # Final dropout before output layer\n",
    "\n",
    "    CCE = CategoricalCrossentropy(from_logits=False, label_smoothing=0.0, axis=-1, reduction=\"sum_over_batch_size\", name=\"categorical_crossentropy\")\n",
    "    model.compile(optimizer='adam', loss=CCE, metrics=[\"accuracy\"])\n",
    "  \n",
    "    return model\n",
    "\n",
    "def load_labels(path):\n",
    "    with open(path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        labels = list(reader)\n",
    "    labels = [i.lstrip() for i in labels[0]]\n",
    "    labels = labels[:-1]\n",
    "    labels_dataframe = pd.DataFrame(labels)\n",
    "    y = pd.get_dummies(labels)\n",
    "    return y, labels_dataframe\n",
    "\n",
    "def load_imgs(path, y, datakind, width):\n",
    "    images = []\n",
    "    for i in tqdm(range(len(y))):\n",
    "        img = image.load_img(f\"{path}{datakind}_img_{str(i)}.png\", target_size=(width, width, 1), color_mode=\"grayscale\")\n",
    "        img = image.img_to_array(img) / 255\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "def class_weight_computer(labels_dataframe):\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels_dataframe), y=labels_dataframe[0])\n",
    "    class_weights = dict(zip(np.unique(labels_dataframe), weights))\n",
    "    class_weights = {i: val for i, val in enumerate(class_weights.values())}\n",
    "    return weights, class_weights\n",
    "\n",
    "def model_execute(X_train, y_train, X_test, y_test, model, epochs, batch_size, classifier, width, class_weights):\n",
    "    saving_address = f'Models50/mchs/{classifier}_{width}_model_best_weights.keras'\n",
    "    from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "    rlrop = ReduceLROnPlateau(monitor='loss', patience=5, factor=0.2, min_lr=0.001)\n",
    "    mch = ModelCheckpoint(saving_address, monitor='loss', mode='min', save_best_only=True)\n",
    "  \n",
    "    history = model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), callbacks=[es, rlrop, mch])\n",
    "    return history, mch\n",
    "\n",
    "def plot_model_history(history, classifier, width, metric, figname):\n",
    "    plt.plot(history.history[metric], color='blue')\n",
    "    plt.plot(history.history[f'val_{metric}'], color='green')\n",
    "    plt.title(label=f\"{metric} on Train and Validation Data: {classifier} {width}\")\n",
    "    plt.legend([metric, f'Validation {metric}'])\n",
    "    plt.savefig(f\"{figname}.png\")\n",
    "\n",
    "def build_ensemble(input_shape, num_classes, ensemble_size=3):\n",
    "    conv_layers1 = [(32, (3, 3)), (64, (3, 3))]\n",
    "    dense_layers1 = [256, 128]\n",
    "    dropout_rates1 = [0.015, 0.005, 0.01, 0.01, 0.1]  # conv1, conv2, dense1, final dropout\n",
    "\n",
    "    conv_layers2 = [(32, (5, 5))]\n",
    "    dense_layers2 = [256, 128]\n",
    "    dropout_rates2 = [0.015, 0.015, 0.01, 0.01]  # conv1, dense1, final dropout\n",
    "\n",
    "    conv_layers3 = [(32, (3, 3)), (64, (3, 3)), (128, (3, 3))]\n",
    "    dense_layers3 = [256, 128]\n",
    "    dropout_rates3 = [0.015, 0.015, 0.01, 0.01, 0.01, 0.01]  # conv1, conv2, conv3, dense1, final dropout\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for i in range(ensemble_size):\n",
    "        if i % 3 == 0:\n",
    "            model = build_model(input_shape, conv_layers1, dense_layers1, dropout_rates1, 'softmax', num_classes)\n",
    "        elif i % 3 == 1:\n",
    "            model = build_model(input_shape, conv_layers2, dense_layers2, dropout_rates2, 'softmax', num_classes)\n",
    "        else:\n",
    "            model = build_model(input_shape, conv_layers3, dense_layers3, dropout_rates3, 'softmax', num_classes)\n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def build_single(input_shape, num_classes):\n",
    "    conv_layers1 = [(32, (3, 3)), (64, (3, 3))]\n",
    "    dense_layers1 = [256, 128]\n",
    "    dropout_rates1 = [0.015, 0.005, 0.01, 0.01]  # conv1, conv2, dense1, final dropout\n",
    "\n",
    "    conv_layers2 = [(32, (5, 5))]\n",
    "    dense_layers2 = [256, 128]\n",
    "    dropout_rates2 = [0.015, 0.01, 0.01]  # conv1, dense1, final dropout\n",
    "\n",
    "    model = build_model(input_shape, conv_layers1, dense_layers1, dropout_rates1, 'softmax', num_classes)\n",
    "    return model\n",
    "\n",
    "def duration_time_finalizer(classifier_name = str, t1=float):\n",
    "    import time\n",
    "    \"\"\"finalizing the time duration from t1 to the time dunction called\n",
    "    and showing the duration.\"\"\"\n",
    "    t2 = time.time()\n",
    "    fitting_time = t2 - t1\n",
    "    fitting_time = time.strftime(\"%H:%M:%S\", time.gmtime(fitting_time))\n",
    "    print(f\"{classifier_name} Runtime: {fitting_time}\")\n",
    "    return fitting_time\n",
    "\n",
    "# Sample usage\n",
    "width = 32\n",
    "input_shape = (width, width, 1)\n",
    "num_classes = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensemble Methods Function Definition\n",
    "def ensemble_hard_voting(models, X_train, y_train):\n",
    "    voting_clf = VotingClassifier(estimators=models, voting='hard')\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    return voting_clf\n",
    "\n",
    "\n",
    "def ensemble_soft_voting(models, X_train, y_train):\n",
    "    voting_clf = VotingClassifier(estimators=models, voting='soft')\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    return voting_clf\n",
    "\n",
    "\n",
    "def ensemble_bagging(base_model, X_train, y_train):\n",
    "    bagging_clf = BaggingClassifier(base_estimator=base_model, n_estimators=10, random_state=42)\n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    return bagging_clf\n",
    "\n",
    "\n",
    "def ensemble_stacking_sklearn(models, meta_model, X_train, y_train):\n",
    "    stacking_clf = StackingClassifier(estimators=models, final_estimator=meta_model, stack_method='predict_proba')\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    return stacking_clf\n",
    "\n",
    "\n",
    "def ensemble_stacking_mlxtend(models, meta_model, X_train, y_train):\n",
    "    stack = MLXTStackingClassifier(classifiers=[model[1] for model in models], meta_classifier=meta_model, use_probas=True)\n",
    "    stack.fit(X_train, y_train)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data\n",
    "        #ETCs\n",
    "train_data_dir_ETC = \"B:/Thesis/Codes & Data/Main/ETC50_imgs/train_size_32/\"\n",
    "test_data_dir_ETC = \"B:/Thesis/Codes & Data/Main/ETC50_imgs/test_size_32/\"\n",
    "train_labels_file_ETC = \"B:/Thesis/Codes & Data/Main/ETC50_imgs/train_size_32/train_img_labels.csv\"\n",
    "test_labels_file_ETC = \"B:/Thesis/Codes & Data/Main/ETC50_imgs/test_size_32/test_img_labels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25040/25040 [04:43<00:00, 88.34it/s] \n",
      "100%|██████████| 10732/10732 [02:07<00:00, 84.22it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adware</th>\n",
       "      <th>Backdoor</th>\n",
       "      <th>Banker</th>\n",
       "      <th>Benign</th>\n",
       "      <th>Dropper</th>\n",
       "      <th>FileInfector</th>\n",
       "      <th>NoCategory</th>\n",
       "      <th>PUA</th>\n",
       "      <th>Ransomware</th>\n",
       "      <th>Riskware</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Scareware</th>\n",
       "      <th>Spy</th>\n",
       "      <th>Trojan</th>\n",
       "      <th>Zeroday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8188</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17636</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19286</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20032 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Adware  Backdoor  Banker  Benign  Dropper  FileInfector  NoCategory  \\\n",
       "8188    False     False   False    True    False         False       False   \n",
       "17636   False     False   False   False    False         False       False   \n",
       "4024    False     False   False    True    False         False       False   \n",
       "7175    False     False   False    True    False         False       False   \n",
       "19286   False     False   False    True    False         False       False   \n",
       "...       ...       ...     ...     ...      ...           ...         ...   \n",
       "21575   False     False   False   False    False         False       False   \n",
       "5390    False     False   False    True    False         False       False   \n",
       "860     False     False   False   False    False         False       False   \n",
       "15795   False     False   False   False    False         False       False   \n",
       "23654   False     False   False   False    False         False       False   \n",
       "\n",
       "         PUA  Ransomware  Riskware    SMS  Scareware    Spy  Trojan  Zeroday  \n",
       "8188   False       False     False  False      False  False   False    False  \n",
       "17636  False       False      True  False      False  False   False    False  \n",
       "4024   False       False     False  False      False  False   False    False  \n",
       "7175   False       False     False  False      False  False   False    False  \n",
       "19286  False       False     False  False      False  False   False    False  \n",
       "...      ...         ...       ...    ...        ...    ...     ...      ...  \n",
       "21575  False       False     False  False      False  False    True    False  \n",
       "5390   False       False     False  False      False  False   False    False  \n",
       "860    False       False      True  False      False  False   False    False  \n",
       "15795  False       False     False  False      False  False   False     True  \n",
       "23654  False       False      True  False      False  False   False    False  \n",
       "\n",
       "[20032 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "#train_ETC\n",
    "y_train_ETC, train_label_dataframe_ETC = load_labels(train_labels_file_ETC)\n",
    "X_train_ETC = load_imgs(train_data_dir_ETC, y_train_ETC, datakind=\"train\", width=32)\n",
    "X_train_ETC, X_val_ETC, y_train_ETC, y_val_ETC = train_test_split(X_train_ETC, y_train_ETC, random_state=42, test_size=0.2)\n",
    "#test_ETC:\n",
    "y_test_ETC, test_label_dataframe_ETC = load_labels(test_labels_file_ETC)\n",
    "X_test_ETC = load_imgs(test_data_dir_ETC, y_test_ETC, datakind=\"test\", width=32)\n",
    "#Sample\n",
    "y_train_ETC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_labels_file_ETC) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    labels = list(reader)\n",
    "labels = [i.lstrip() for i in labels[0]]\n",
    "labels = labels[:-1]\n",
    "labels_dataframe = pd.DataFrame(labels)\n",
    "labels_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20032, 15), (25040, 1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_ETC.shape, train_label_dataframe_ETC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = build_ensemble(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model #1 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 124ms/step - accuracy: 0.6312 - loss: 2.6142 - val_accuracy: 0.8259 - val_loss: 0.6027 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.7692 - loss: 2.0181 - val_accuracy: 0.8610 - val_loss: 0.5101 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.7895 - loss: 2.0263 - val_accuracy: 0.8680 - val_loss: 0.4628 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.7938 - loss: 1.9541 - val_accuracy: 0.8760 - val_loss: 0.4379 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.8036 - loss: 1.8946 - val_accuracy: 0.8756 - val_loss: 0.4303 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 117ms/step - accuracy: 0.8071 - loss: 1.9281 - val_accuracy: 0.8806 - val_loss: 0.4251 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - accuracy: 0.8140 - loss: 1.8990 - val_accuracy: 0.8802 - val_loss: 0.4031 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 122ms/step - accuracy: 0.8171 - loss: 1.8627 - val_accuracy: 0.8832 - val_loss: 0.4058 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 145ms/step - accuracy: 0.8254 - loss: 1.7768 - val_accuracy: 0.8854 - val_loss: 0.4121 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8205 - loss: 1.8458 - val_accuracy: 0.8862 - val_loss: 0.4068 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.8271 - loss: 1.8240 - val_accuracy: 0.8790 - val_loss: 0.4178 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8332 - loss: 1.7578 - val_accuracy: 0.8880 - val_loss: 0.4267 - learning_rate: 0.0010\n",
      "the model #2 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 136ms/step - accuracy: 0.7063 - loss: 1.1825 - val_accuracy: 0.8427 - val_loss: 0.5557 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.8515 - loss: 0.6259 - val_accuracy: 0.8658 - val_loss: 0.4588 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.8702 - loss: 0.5456 - val_accuracy: 0.8694 - val_loss: 0.4423 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 134ms/step - accuracy: 0.8775 - loss: 0.5236 - val_accuracy: 0.8760 - val_loss: 0.4128 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 132ms/step - accuracy: 0.8849 - loss: 0.5016 - val_accuracy: 0.8796 - val_loss: 0.4065 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 131ms/step - accuracy: 0.8897 - loss: 0.4671 - val_accuracy: 0.8840 - val_loss: 0.3999 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 123ms/step - accuracy: 0.8991 - loss: 0.4303 - val_accuracy: 0.8848 - val_loss: 0.3999 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.8992 - loss: 0.4605 - val_accuracy: 0.8854 - val_loss: 0.4122 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 161ms/step - accuracy: 0.9036 - loss: 0.4416 - val_accuracy: 0.8864 - val_loss: 0.4027 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 164ms/step - accuracy: 0.9060 - loss: 0.4375 - val_accuracy: 0.8824 - val_loss: 0.4222 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 147ms/step - accuracy: 0.9101 - loss: 0.3895 - val_accuracy: 0.8878 - val_loss: 0.4073 - learning_rate: 0.0010\n",
      "the model #3 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 162ms/step - accuracy: 0.6328 - loss: 1.5336 - val_accuracy: 0.8011 - val_loss: 0.6945 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.8164 - loss: 0.7706 - val_accuracy: 0.8367 - val_loss: 0.5819 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 203ms/step - accuracy: 0.8460 - loss: 0.6622 - val_accuracy: 0.8634 - val_loss: 0.4908 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 187ms/step - accuracy: 0.8630 - loss: 0.6111 - val_accuracy: 0.8686 - val_loss: 0.4552 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 159ms/step - accuracy: 0.8713 - loss: 0.5692 - val_accuracy: 0.8758 - val_loss: 0.4310 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 155ms/step - accuracy: 0.8787 - loss: 0.5418 - val_accuracy: 0.8722 - val_loss: 0.4282 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.8830 - loss: 0.5024 - val_accuracy: 0.8818 - val_loss: 0.4079 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 165ms/step - accuracy: 0.8876 - loss: 0.4975 - val_accuracy: 0.8758 - val_loss: 0.4180 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 177ms/step - accuracy: 0.8927 - loss: 0.4563 - val_accuracy: 0.8830 - val_loss: 0.4220 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 181ms/step - accuracy: 0.8971 - loss: 0.4500 - val_accuracy: 0.8800 - val_loss: 0.4225 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.8994 - loss: 0.4697 - val_accuracy: 0.8798 - val_loss: 0.4280 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8982 - loss: 0.4493 - val_accuracy: 0.8844 - val_loss: 0.4052 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 166ms/step - accuracy: 0.9043 - loss: 0.4381 - val_accuracy: 0.8788 - val_loss: 0.4368 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 182ms/step - accuracy: 0.9080 - loss: 0.4075 - val_accuracy: 0.8826 - val_loss: 0.4300 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.9108 - loss: 0.4111 - val_accuracy: 0.8876 - val_loss: 0.4720 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 174ms/step - accuracy: 0.9091 - loss: 0.4135 - val_accuracy: 0.8812 - val_loss: 0.4329 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 178ms/step - accuracy: 0.9143 - loss: 0.3943 - val_accuracy: 0.8840 - val_loss: 0.4582 - learning_rate: 0.0010\n",
      "the model #4 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 157ms/step - accuracy: 0.5973 - loss: 2.6112 - val_accuracy: 0.8393 - val_loss: 0.5783 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 165ms/step - accuracy: 0.7673 - loss: 2.0683 - val_accuracy: 0.8592 - val_loss: 0.4962 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 160ms/step - accuracy: 0.7875 - loss: 1.9711 - val_accuracy: 0.8726 - val_loss: 0.4417 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 160ms/step - accuracy: 0.7967 - loss: 1.9018 - val_accuracy: 0.8780 - val_loss: 0.4225 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 172ms/step - accuracy: 0.8076 - loss: 1.8648 - val_accuracy: 0.8822 - val_loss: 0.4198 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - accuracy: 0.8000 - loss: 1.9814 - val_accuracy: 0.8746 - val_loss: 0.4185 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - accuracy: 0.8106 - loss: 1.9390 - val_accuracy: 0.8834 - val_loss: 0.4112 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - accuracy: 0.8170 - loss: 1.8515 - val_accuracy: 0.8812 - val_loss: 0.3964 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 181ms/step - accuracy: 0.8198 - loss: 1.9015 - val_accuracy: 0.8816 - val_loss: 0.4097 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 175ms/step - accuracy: 0.8256 - loss: 1.7731 - val_accuracy: 0.8810 - val_loss: 0.4116 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 170ms/step - accuracy: 0.8279 - loss: 1.8378 - val_accuracy: 0.8862 - val_loss: 0.4222 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.8260 - loss: 1.8272 - val_accuracy: 0.8840 - val_loss: 0.4291 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8305 - loss: 1.8285 - val_accuracy: 0.8910 - val_loss: 0.4175 - learning_rate: 0.0010\n",
      "the model #5 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 143ms/step - accuracy: 0.7129 - loss: 1.1948 - val_accuracy: 0.8253 - val_loss: 0.5637 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 165ms/step - accuracy: 0.8565 - loss: 0.6164 - val_accuracy: 0.8570 - val_loss: 0.4858 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.8698 - loss: 0.5308 - val_accuracy: 0.8752 - val_loss: 0.4379 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.8761 - loss: 0.5147 - val_accuracy: 0.8794 - val_loss: 0.4180 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.8810 - loss: 0.5124 - val_accuracy: 0.8822 - val_loss: 0.4147 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.8923 - loss: 0.4858 - val_accuracy: 0.8834 - val_loss: 0.4004 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 167ms/step - accuracy: 0.8932 - loss: 0.4461 - val_accuracy: 0.8856 - val_loss: 0.4046 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 162ms/step - accuracy: 0.8973 - loss: 0.4787 - val_accuracy: 0.8802 - val_loss: 0.4084 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 168ms/step - accuracy: 0.9017 - loss: 0.4452 - val_accuracy: 0.8820 - val_loss: 0.4005 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 162ms/step - accuracy: 0.9079 - loss: 0.4289 - val_accuracy: 0.8832 - val_loss: 0.4120 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 120ms/step - accuracy: 0.9074 - loss: 0.4064 - val_accuracy: 0.8840 - val_loss: 0.4082 - learning_rate: 0.0010\n",
      "the model #6 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 206ms/step - accuracy: 0.6045 - loss: 1.4892 - val_accuracy: 0.8109 - val_loss: 0.6770 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.8201 - loss: 0.7609 - val_accuracy: 0.8476 - val_loss: 0.5516 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.8500 - loss: 0.6385 - val_accuracy: 0.8644 - val_loss: 0.4806 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.8701 - loss: 0.5807 - val_accuracy: 0.8708 - val_loss: 0.4523 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.8784 - loss: 0.5196 - val_accuracy: 0.8684 - val_loss: 0.4468 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.8780 - loss: 0.5320 - val_accuracy: 0.8676 - val_loss: 0.4528 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.8858 - loss: 0.5076 - val_accuracy: 0.8814 - val_loss: 0.4141 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.8955 - loss: 0.4756 - val_accuracy: 0.8774 - val_loss: 0.4208 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 186ms/step - accuracy: 0.8903 - loss: 0.4767 - val_accuracy: 0.8730 - val_loss: 0.4275 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 200ms/step - accuracy: 0.8982 - loss: 0.4433 - val_accuracy: 0.8764 - val_loss: 0.4311 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.9000 - loss: 0.4503 - val_accuracy: 0.8844 - val_loss: 0.4208 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 207ms/step - accuracy: 0.9057 - loss: 0.4130 - val_accuracy: 0.8816 - val_loss: 0.4251 - learning_rate: 0.0010\n",
      "the model #7 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 188ms/step - accuracy: 0.6187 - loss: 2.6222 - val_accuracy: 0.8273 - val_loss: 0.5911 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 212ms/step - accuracy: 0.7713 - loss: 2.0458 - val_accuracy: 0.8568 - val_loss: 0.4908 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 219ms/step - accuracy: 0.7831 - loss: 2.0221 - val_accuracy: 0.8664 - val_loss: 0.4631 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 232ms/step - accuracy: 0.7894 - loss: 1.9848 - val_accuracy: 0.8728 - val_loss: 0.4318 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 256ms/step - accuracy: 0.7951 - loss: 1.9970 - val_accuracy: 0.8742 - val_loss: 0.4400 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 286ms/step - accuracy: 0.8091 - loss: 1.8758 - val_accuracy: 0.8808 - val_loss: 0.4308 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 233ms/step - accuracy: 0.8113 - loss: 1.9001 - val_accuracy: 0.8742 - val_loss: 0.4450 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 260ms/step - accuracy: 0.8131 - loss: 1.8304 - val_accuracy: 0.8848 - val_loss: 0.4090 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.8188 - loss: 1.8493 - val_accuracy: 0.8862 - val_loss: 0.4099 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 262ms/step - accuracy: 0.8184 - loss: 1.8908 - val_accuracy: 0.8814 - val_loss: 0.4160 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 266ms/step - accuracy: 0.8295 - loss: 1.7687 - val_accuracy: 0.8834 - val_loss: 0.4030 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.8317 - loss: 1.7759 - val_accuracy: 0.8852 - val_loss: 0.4165 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 257ms/step - accuracy: 0.8354 - loss: 1.7689 - val_accuracy: 0.8842 - val_loss: 0.4258 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 265ms/step - accuracy: 0.8285 - loss: 1.8481 - val_accuracy: 0.8842 - val_loss: 0.4320 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 286ms/step - accuracy: 0.8386 - loss: 1.7653 - val_accuracy: 0.8872 - val_loss: 0.4208 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 258ms/step - accuracy: 0.8405 - loss: 1.7404 - val_accuracy: 0.8864 - val_loss: 0.4314 - learning_rate: 0.0010\n",
      "the model #8 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 191ms/step - accuracy: 0.6973 - loss: 1.1500 - val_accuracy: 0.8482 - val_loss: 0.5262 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 221ms/step - accuracy: 0.8559 - loss: 0.6109 - val_accuracy: 0.8672 - val_loss: 0.4623 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 264ms/step - accuracy: 0.8701 - loss: 0.5488 - val_accuracy: 0.8764 - val_loss: 0.4245 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 204ms/step - accuracy: 0.8772 - loss: 0.5303 - val_accuracy: 0.8792 - val_loss: 0.4193 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.8816 - loss: 0.5065 - val_accuracy: 0.8848 - val_loss: 0.3993 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.8935 - loss: 0.4583 - val_accuracy: 0.8842 - val_loss: 0.4021 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 189ms/step - accuracy: 0.8969 - loss: 0.4330 - val_accuracy: 0.8832 - val_loss: 0.4089 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 213ms/step - accuracy: 0.8973 - loss: 0.4412 - val_accuracy: 0.8870 - val_loss: 0.3967 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 201ms/step - accuracy: 0.9035 - loss: 0.4425 - val_accuracy: 0.8832 - val_loss: 0.4008 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 226ms/step - accuracy: 0.9102 - loss: 0.4079 - val_accuracy: 0.8850 - val_loss: 0.4125 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 167ms/step - accuracy: 0.9143 - loss: 0.3643 - val_accuracy: 0.8886 - val_loss: 0.4095 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.9118 - loss: 0.3970 - val_accuracy: 0.8864 - val_loss: 0.4320 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 284ms/step - accuracy: 0.9139 - loss: 0.4198 - val_accuracy: 0.8926 - val_loss: 0.4181 - learning_rate: 0.0010\n",
      "the model #9 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 276ms/step - accuracy: 0.6067 - loss: 1.5187 - val_accuracy: 0.7975 - val_loss: 0.7222 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 226ms/step - accuracy: 0.8240 - loss: 0.7581 - val_accuracy: 0.8333 - val_loss: 0.5834 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 229ms/step - accuracy: 0.8534 - loss: 0.6274 - val_accuracy: 0.8698 - val_loss: 0.4820 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 226ms/step - accuracy: 0.8611 - loss: 0.6177 - val_accuracy: 0.8732 - val_loss: 0.4492 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 248ms/step - accuracy: 0.8730 - loss: 0.5514 - val_accuracy: 0.8720 - val_loss: 0.4468 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 362ms/step - accuracy: 0.8812 - loss: 0.5239 - val_accuracy: 0.8764 - val_loss: 0.4240 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 396ms/step - accuracy: 0.8881 - loss: 0.5244 - val_accuracy: 0.8776 - val_loss: 0.4263 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 395ms/step - accuracy: 0.8904 - loss: 0.4782 - val_accuracy: 0.8762 - val_loss: 0.4309 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 413ms/step - accuracy: 0.8918 - loss: 0.4482 - val_accuracy: 0.8806 - val_loss: 0.4442 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 406ms/step - accuracy: 0.8964 - loss: 0.4718 - val_accuracy: 0.8786 - val_loss: 0.4305 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 353ms/step - accuracy: 0.9010 - loss: 0.4507 - val_accuracy: 0.8806 - val_loss: 0.4312 - learning_rate: 0.0010\n",
      "the model #10 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 292ms/step - accuracy: 0.6332 - loss: 2.5929 - val_accuracy: 0.8313 - val_loss: 0.5886 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.7667 - loss: 2.0312 - val_accuracy: 0.8600 - val_loss: 0.4887 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 307ms/step - accuracy: 0.7910 - loss: 1.9388 - val_accuracy: 0.8676 - val_loss: 0.4524 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 358ms/step - accuracy: 0.8009 - loss: 1.9016 - val_accuracy: 0.8776 - val_loss: 0.4409 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 375ms/step - accuracy: 0.7985 - loss: 2.0024 - val_accuracy: 0.8720 - val_loss: 0.4325 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 376ms/step - accuracy: 0.8088 - loss: 1.9223 - val_accuracy: 0.8792 - val_loss: 0.4191 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 378ms/step - accuracy: 0.8115 - loss: 1.9263 - val_accuracy: 0.8850 - val_loss: 0.4092 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 345ms/step - accuracy: 0.8181 - loss: 1.8672 - val_accuracy: 0.8838 - val_loss: 0.4205 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 315ms/step - accuracy: 0.8177 - loss: 1.8673 - val_accuracy: 0.8788 - val_loss: 0.4109 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 277ms/step - accuracy: 0.8254 - loss: 1.8194 - val_accuracy: 0.8862 - val_loss: 0.4134 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 318ms/step - accuracy: 0.8291 - loss: 1.8685 - val_accuracy: 0.8806 - val_loss: 0.4167 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 250ms/step - accuracy: 0.8268 - loss: 1.8829 - val_accuracy: 0.8850 - val_loss: 0.4222 - learning_rate: 0.0010\n",
      "the model #11 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 171ms/step - accuracy: 0.7078 - loss: 1.2272 - val_accuracy: 0.8516 - val_loss: 0.5356 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 206ms/step - accuracy: 0.8508 - loss: 0.6585 - val_accuracy: 0.8644 - val_loss: 0.4579 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 177ms/step - accuracy: 0.8654 - loss: 0.5693 - val_accuracy: 0.8770 - val_loss: 0.4317 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 143ms/step - accuracy: 0.8740 - loss: 0.5282 - val_accuracy: 0.8760 - val_loss: 0.4206 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 142ms/step - accuracy: 0.8826 - loss: 0.4984 - val_accuracy: 0.8758 - val_loss: 0.4080 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.8874 - loss: 0.4820 - val_accuracy: 0.8828 - val_loss: 0.3939 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 146ms/step - accuracy: 0.8921 - loss: 0.4622 - val_accuracy: 0.8814 - val_loss: 0.4044 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 155ms/step - accuracy: 0.8983 - loss: 0.4323 - val_accuracy: 0.8854 - val_loss: 0.4082 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 227ms/step - accuracy: 0.9050 - loss: 0.4312 - val_accuracy: 0.8896 - val_loss: 0.4018 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 193ms/step - accuracy: 0.9060 - loss: 0.4280 - val_accuracy: 0.8894 - val_loss: 0.3994 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 456ms/step - accuracy: 0.9086 - loss: 0.3918 - val_accuracy: 0.8904 - val_loss: 0.4014 - learning_rate: 0.0010\n",
      "the model #12 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 380ms/step - accuracy: 0.6465 - loss: 1.5147 - val_accuracy: 0.8109 - val_loss: 0.6832 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 369ms/step - accuracy: 0.8153 - loss: 0.7498 - val_accuracy: 0.8504 - val_loss: 0.5333 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 370ms/step - accuracy: 0.8480 - loss: 0.6488 - val_accuracy: 0.8688 - val_loss: 0.4685 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 383ms/step - accuracy: 0.8686 - loss: 0.5684 - val_accuracy: 0.8680 - val_loss: 0.4523 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 403ms/step - accuracy: 0.8752 - loss: 0.5552 - val_accuracy: 0.8746 - val_loss: 0.4291 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 424ms/step - accuracy: 0.8796 - loss: 0.5250 - val_accuracy: 0.8790 - val_loss: 0.4084 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 221ms/step - accuracy: 0.8877 - loss: 0.4798 - val_accuracy: 0.8798 - val_loss: 0.4170 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 208ms/step - accuracy: 0.8847 - loss: 0.4985 - val_accuracy: 0.8776 - val_loss: 0.4132 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 194ms/step - accuracy: 0.8920 - loss: 0.4733 - val_accuracy: 0.8802 - val_loss: 0.4127 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 190ms/step - accuracy: 0.8963 - loss: 0.4797 - val_accuracy: 0.8780 - val_loss: 0.4154 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.9042 - loss: 0.4274 - val_accuracy: 0.8838 - val_loss: 0.4166 - learning_rate: 0.0010\n",
      "the model #13 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 166ms/step - accuracy: 0.6185 - loss: 2.6446 - val_accuracy: 0.8161 - val_loss: 0.6029 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 188ms/step - accuracy: 0.7719 - loss: 2.0175 - val_accuracy: 0.8129 - val_loss: 0.5534 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 266ms/step - accuracy: 0.7885 - loss: 1.9413 - val_accuracy: 0.8666 - val_loss: 0.4682 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 227ms/step - accuracy: 0.7940 - loss: 1.9684 - val_accuracy: 0.8762 - val_loss: 0.4393 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.7962 - loss: 1.9830 - val_accuracy: 0.8814 - val_loss: 0.4252 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 228ms/step - accuracy: 0.8082 - loss: 1.9652 - val_accuracy: 0.8790 - val_loss: 0.4171 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 224ms/step - accuracy: 0.8137 - loss: 1.8678 - val_accuracy: 0.8792 - val_loss: 0.4325 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 211ms/step - accuracy: 0.8142 - loss: 1.8827 - val_accuracy: 0.8764 - val_loss: 0.4095 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 225ms/step - accuracy: 0.8177 - loss: 1.8461 - val_accuracy: 0.8814 - val_loss: 0.4248 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 211ms/step - accuracy: 0.8258 - loss: 1.8513 - val_accuracy: 0.8858 - val_loss: 0.4092 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 227ms/step - accuracy: 0.8257 - loss: 1.8614 - val_accuracy: 0.8876 - val_loss: 0.3984 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 228ms/step - accuracy: 0.8308 - loss: 1.8118 - val_accuracy: 0.8844 - val_loss: 0.4133 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 222ms/step - accuracy: 0.8337 - loss: 1.8289 - val_accuracy: 0.8864 - val_loss: 0.4271 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 206ms/step - accuracy: 0.8283 - loss: 1.8627 - val_accuracy: 0.8872 - val_loss: 0.4249 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 205ms/step - accuracy: 0.8366 - loss: 1.8449 - val_accuracy: 0.8840 - val_loss: 0.4471 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 214ms/step - accuracy: 0.8407 - loss: 1.8158 - val_accuracy: 0.8862 - val_loss: 0.4491 - learning_rate: 0.0010\n",
      "the model #14 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 162ms/step - accuracy: 0.7311 - loss: 1.1872 - val_accuracy: 0.8518 - val_loss: 0.5152 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 163ms/step - accuracy: 0.8540 - loss: 0.6248 - val_accuracy: 0.8618 - val_loss: 0.4645 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 156ms/step - accuracy: 0.8686 - loss: 0.5712 - val_accuracy: 0.8752 - val_loss: 0.4337 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 151ms/step - accuracy: 0.8778 - loss: 0.5394 - val_accuracy: 0.8498 - val_loss: 0.4473 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 145ms/step - accuracy: 0.8797 - loss: 0.5279 - val_accuracy: 0.8834 - val_loss: 0.4074 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 155ms/step - accuracy: 0.8906 - loss: 0.4941 - val_accuracy: 0.8874 - val_loss: 0.3977 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 157ms/step - accuracy: 0.8937 - loss: 0.4583 - val_accuracy: 0.8850 - val_loss: 0.4076 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 147ms/step - accuracy: 0.8981 - loss: 0.4424 - val_accuracy: 0.8836 - val_loss: 0.3989 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 144ms/step - accuracy: 0.9045 - loss: 0.4398 - val_accuracy: 0.8890 - val_loss: 0.4047 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.9070 - loss: 0.4142 - val_accuracy: 0.8916 - val_loss: 0.3941 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 146ms/step - accuracy: 0.9078 - loss: 0.4024 - val_accuracy: 0.8830 - val_loss: 0.4313 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 147ms/step - accuracy: 0.9134 - loss: 0.3772 - val_accuracy: 0.8890 - val_loss: 0.4173 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 142ms/step - accuracy: 0.9162 - loss: 0.4124 - val_accuracy: 0.8888 - val_loss: 0.4259 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 141ms/step - accuracy: 0.9210 - loss: 0.3810 - val_accuracy: 0.8848 - val_loss: 0.4401 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 142ms/step - accuracy: 0.9236 - loss: 0.3625 - val_accuracy: 0.8910 - val_loss: 0.4504 - learning_rate: 0.0010\n",
      "the model #15 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 193ms/step - accuracy: 0.6080 - loss: 1.5223 - val_accuracy: 0.8087 - val_loss: 0.6711 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.8174 - loss: 0.7736 - val_accuracy: 0.8542 - val_loss: 0.5349 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8612 - loss: 0.6249 - val_accuracy: 0.8654 - val_loss: 0.4852 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.8674 - loss: 0.5616 - val_accuracy: 0.8744 - val_loss: 0.4544 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 197ms/step - accuracy: 0.8777 - loss: 0.5233 - val_accuracy: 0.8716 - val_loss: 0.4500 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8869 - loss: 0.4849 - val_accuracy: 0.8742 - val_loss: 0.4316 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 206ms/step - accuracy: 0.8831 - loss: 0.5102 - val_accuracy: 0.8794 - val_loss: 0.4260 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 218ms/step - accuracy: 0.8922 - loss: 0.4860 - val_accuracy: 0.8784 - val_loss: 0.4217 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 216ms/step - accuracy: 0.8921 - loss: 0.4678 - val_accuracy: 0.8778 - val_loss: 0.4257 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 209ms/step - accuracy: 0.8963 - loss: 0.4443 - val_accuracy: 0.8770 - val_loss: 0.4561 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9010 - loss: 0.4483 - val_accuracy: 0.8826 - val_loss: 0.4149 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 210ms/step - accuracy: 0.9035 - loss: 0.4254 - val_accuracy: 0.8696 - val_loss: 0.4531 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 222ms/step - accuracy: 0.9058 - loss: 0.4229 - val_accuracy: 0.8838 - val_loss: 0.4232 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 233ms/step - accuracy: 0.9079 - loss: 0.3970 - val_accuracy: 0.8832 - val_loss: 0.4291 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 222ms/step - accuracy: 0.9087 - loss: 0.4102 - val_accuracy: 0.8808 - val_loss: 0.4490 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 220ms/step - accuracy: 0.9117 - loss: 0.4097 - val_accuracy: 0.8806 - val_loss: 0.4529 - learning_rate: 0.0010\n",
      "the model #16 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 204ms/step - accuracy: 0.6105 - loss: 2.5980 - val_accuracy: 0.8241 - val_loss: 0.5976 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 343ms/step - accuracy: 0.7662 - loss: 2.0788 - val_accuracy: 0.8574 - val_loss: 0.5083 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 309ms/step - accuracy: 0.7814 - loss: 2.0314 - val_accuracy: 0.8700 - val_loss: 0.4505 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 367ms/step - accuracy: 0.7936 - loss: 1.9427 - val_accuracy: 0.8728 - val_loss: 0.4415 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 360ms/step - accuracy: 0.8008 - loss: 1.9842 - val_accuracy: 0.8748 - val_loss: 0.4280 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 0.8020 - loss: 1.9219 - val_accuracy: 0.8818 - val_loss: 0.4174 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 323ms/step - accuracy: 0.8097 - loss: 1.9273 - val_accuracy: 0.8796 - val_loss: 0.4137 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 317ms/step - accuracy: 0.8120 - loss: 1.8627 - val_accuracy: 0.8834 - val_loss: 0.4079 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 309ms/step - accuracy: 0.8120 - loss: 1.9830 - val_accuracy: 0.8758 - val_loss: 0.4322 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 299ms/step - accuracy: 0.8171 - loss: 1.8695 - val_accuracy: 0.8880 - val_loss: 0.4254 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 341ms/step - accuracy: 0.8245 - loss: 1.8296 - val_accuracy: 0.8872 - val_loss: 0.4198 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 287ms/step - accuracy: 0.8356 - loss: 1.6906 - val_accuracy: 0.8858 - val_loss: 0.4289 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 324ms/step - accuracy: 0.8311 - loss: 1.8304 - val_accuracy: 0.8790 - val_loss: 0.4335 - learning_rate: 0.0010\n",
      "the model #17 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 260ms/step - accuracy: 0.7048 - loss: 1.1829 - val_accuracy: 0.8391 - val_loss: 0.5590 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 251ms/step - accuracy: 0.8589 - loss: 0.6066 - val_accuracy: 0.8700 - val_loss: 0.4569 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 223ms/step - accuracy: 0.8681 - loss: 0.5547 - val_accuracy: 0.8724 - val_loss: 0.4369 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 192ms/step - accuracy: 0.8793 - loss: 0.5097 - val_accuracy: 0.8772 - val_loss: 0.4129 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 306ms/step - accuracy: 0.8825 - loss: 0.5034 - val_accuracy: 0.8768 - val_loss: 0.4250 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 283ms/step - accuracy: 0.8962 - loss: 0.4529 - val_accuracy: 0.8802 - val_loss: 0.4176 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 310ms/step - accuracy: 0.8959 - loss: 0.4456 - val_accuracy: 0.8830 - val_loss: 0.4071 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 265ms/step - accuracy: 0.8983 - loss: 0.4573 - val_accuracy: 0.8892 - val_loss: 0.3975 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 263ms/step - accuracy: 0.9035 - loss: 0.4482 - val_accuracy: 0.8854 - val_loss: 0.4297 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 269ms/step - accuracy: 0.9075 - loss: 0.4091 - val_accuracy: 0.8734 - val_loss: 0.4168 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 199ms/step - accuracy: 0.9051 - loss: 0.4176 - val_accuracy: 0.8850 - val_loss: 0.4046 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 252ms/step - accuracy: 0.9122 - loss: 0.4051 - val_accuracy: 0.8872 - val_loss: 0.4173 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 338ms/step - accuracy: 0.9132 - loss: 0.4262 - val_accuracy: 0.8900 - val_loss: 0.4336 - learning_rate: 0.0010\n",
      "the model #18 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 413ms/step - accuracy: 0.6271 - loss: 1.4663 - val_accuracy: 0.8105 - val_loss: 0.6845 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 380ms/step - accuracy: 0.8208 - loss: 0.7958 - val_accuracy: 0.8460 - val_loss: 0.5609 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 378ms/step - accuracy: 0.8592 - loss: 0.6085 - val_accuracy: 0.8634 - val_loss: 0.4815 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.8663 - loss: 0.6043 - val_accuracy: 0.8710 - val_loss: 0.4496 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 325ms/step - accuracy: 0.8737 - loss: 0.5688 - val_accuracy: 0.8738 - val_loss: 0.4321 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 321ms/step - accuracy: 0.8806 - loss: 0.5226 - val_accuracy: 0.8712 - val_loss: 0.4428 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 308ms/step - accuracy: 0.8872 - loss: 0.4678 - val_accuracy: 0.8788 - val_loss: 0.4184 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 322ms/step - accuracy: 0.8851 - loss: 0.5002 - val_accuracy: 0.8758 - val_loss: 0.4231 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 311ms/step - accuracy: 0.8950 - loss: 0.4643 - val_accuracy: 0.8792 - val_loss: 0.4200 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 295ms/step - accuracy: 0.8982 - loss: 0.4406 - val_accuracy: 0.8780 - val_loss: 0.4330 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 0.9004 - loss: 0.4263 - val_accuracy: 0.8824 - val_loss: 0.4219 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 332ms/step - accuracy: 0.9040 - loss: 0.4388 - val_accuracy: 0.8778 - val_loss: 0.4227 - learning_rate: 0.0010\n",
      "the model #19 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 273ms/step - accuracy: 0.6203 - loss: 2.6040 - val_accuracy: 0.8075 - val_loss: 0.6129 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 309ms/step - accuracy: 0.7662 - loss: 2.1057 - val_accuracy: 0.8626 - val_loss: 0.4868 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 258ms/step - accuracy: 0.7908 - loss: 1.9747 - val_accuracy: 0.8654 - val_loss: 0.4540 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 339ms/step - accuracy: 0.7973 - loss: 1.9261 - val_accuracy: 0.8766 - val_loss: 0.4279 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 239ms/step - accuracy: 0.8075 - loss: 1.9292 - val_accuracy: 0.8746 - val_loss: 0.4190 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 260ms/step - accuracy: 0.8044 - loss: 1.9659 - val_accuracy: 0.8812 - val_loss: 0.4050 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 301ms/step - accuracy: 0.8149 - loss: 1.8469 - val_accuracy: 0.8736 - val_loss: 0.4106 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 255ms/step - accuracy: 0.8112 - loss: 1.9530 - val_accuracy: 0.8848 - val_loss: 0.4001 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 217ms/step - accuracy: 0.8250 - loss: 1.7950 - val_accuracy: 0.8592 - val_loss: 0.4303 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 224ms/step - accuracy: 0.8207 - loss: 1.8573 - val_accuracy: 0.8796 - val_loss: 0.4085 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 247ms/step - accuracy: 0.8267 - loss: 1.8350 - val_accuracy: 0.8850 - val_loss: 0.4211 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 313ms/step - accuracy: 0.8293 - loss: 1.8677 - val_accuracy: 0.8804 - val_loss: 0.4348 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 250ms/step - accuracy: 0.8287 - loss: 1.8057 - val_accuracy: 0.8872 - val_loss: 0.4252 - learning_rate: 0.0010\n",
      "the model #20 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 157ms/step - accuracy: 0.7024 - loss: 1.2395 - val_accuracy: 0.8375 - val_loss: 0.5417 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 151ms/step - accuracy: 0.8546 - loss: 0.6230 - val_accuracy: 0.8616 - val_loss: 0.4726 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 209ms/step - accuracy: 0.8657 - loss: 0.6159 - val_accuracy: 0.8702 - val_loss: 0.4392 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 170ms/step - accuracy: 0.8827 - loss: 0.5074 - val_accuracy: 0.8746 - val_loss: 0.4372 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 195ms/step - accuracy: 0.8805 - loss: 0.4963 - val_accuracy: 0.8794 - val_loss: 0.4070 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 152ms/step - accuracy: 0.8954 - loss: 0.4613 - val_accuracy: 0.8812 - val_loss: 0.4070 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 149ms/step - accuracy: 0.8903 - loss: 0.4674 - val_accuracy: 0.8882 - val_loss: 0.3955 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 152ms/step - accuracy: 0.8970 - loss: 0.4354 - val_accuracy: 0.8818 - val_loss: 0.4076 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 146ms/step - accuracy: 0.9030 - loss: 0.4236 - val_accuracy: 0.8878 - val_loss: 0.4133 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 160ms/step - accuracy: 0.9060 - loss: 0.4379 - val_accuracy: 0.8888 - val_loss: 0.4121 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 183ms/step - accuracy: 0.9125 - loss: 0.4032 - val_accuracy: 0.8884 - val_loss: 0.4160 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - accuracy: 0.9128 - loss: 0.4064 - val_accuracy: 0.8822 - val_loss: 0.4212 - learning_rate: 0.0010\n",
      "the model #21 out of 21 is fitting on trains:\n",
      "Epoch 1/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 230ms/step - accuracy: 0.6384 - loss: 1.4754 - val_accuracy: 0.8115 - val_loss: 0.6568 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 230ms/step - accuracy: 0.8277 - loss: 0.7321 - val_accuracy: 0.8383 - val_loss: 0.5742 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 227ms/step - accuracy: 0.8521 - loss: 0.6273 - val_accuracy: 0.8640 - val_loss: 0.4745 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 219ms/step - accuracy: 0.8666 - loss: 0.5882 - val_accuracy: 0.8748 - val_loss: 0.4353 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 231ms/step - accuracy: 0.8700 - loss: 0.5618 - val_accuracy: 0.8748 - val_loss: 0.4343 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 253ms/step - accuracy: 0.8750 - loss: 0.5646 - val_accuracy: 0.8740 - val_loss: 0.4248 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 248ms/step - accuracy: 0.8846 - loss: 0.4832 - val_accuracy: 0.8810 - val_loss: 0.4162 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 231ms/step - accuracy: 0.8965 - loss: 0.4617 - val_accuracy: 0.8808 - val_loss: 0.4088 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 198ms/step - accuracy: 0.8925 - loss: 0.4773 - val_accuracy: 0.8790 - val_loss: 0.4182 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 191ms/step - accuracy: 0.8982 - loss: 0.4418 - val_accuracy: 0.8848 - val_loss: 0.4148 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 194ms/step - accuracy: 0.9062 - loss: 0.4205 - val_accuracy: 0.8812 - val_loss: 0.4178 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 185ms/step - accuracy: 0.9060 - loss: 0.4161 - val_accuracy: 0.8806 - val_loss: 0.4297 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 194ms/step - accuracy: 0.9109 - loss: 0.3813 - val_accuracy: 0.8776 - val_loss: 0.4451 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "ensemble_size = 21\n",
    "\n",
    "# Build the ensemble models\n",
    "ensemble_models = build_ensemble(input_shape, num_classes, ensemble_size=ensemble_size)\n",
    "fitting_times = []\n",
    "\n",
    "# Execute and save the models\n",
    "for i, model in enumerate(ensemble_models):\n",
    "    t1 = time.time()\n",
    "    print(f\"the model #{i+1} out of {ensemble_size} is fitting on trains:\")\n",
    "    history, _ = model_execute(X_train_ETC, y_train_ETC, X_val_ETC, y_val_ETC, model, epochs=60, batch_size=128, classifier=f\"Model_{i+1}\", width=width, class_weights=None)\n",
    "    plot_model_history(history, f\"Model_{i+1}\", width, \"accuracy\", f\"Model50/figs/model_{i+1}_accuracy_32\")\n",
    "    fitting_times.append(duration_time_finalizer(\"the model #{i+1}\", t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weak model #0\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "weak model #1\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "weak model #2\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "weak model #3\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "weak model #4\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "weak model #5\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "weak model #6\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "weak model #7\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "weak model #8\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "weak model #9\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "weak model #10\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "weak model #11\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step\n",
      "weak model #12\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "weak model #13\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "weak model #14\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n",
      "weak model #15\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "weak model #16\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "weak model #17\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
      "weak model #18\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
      "weak model #19\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "weak model #20\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for ensemble_num in range(ensemble_size):\n",
    "    model_path = f'Models50/mchs/Model_{ensemble_num+1}_32_model_best_weights.keras'\n",
    "    # models[ensemble_num] = build_weak_model1(input_shape=(width, width, 1))  # Recreate the model structure\n",
    "    ensemble_models[ensemble_num].load_weights(model_path)  # Load the saved weights\n",
    "    print(f\"weak model #{ensemble_num}\")\n",
    "    pred.append(ensemble_models[ensemble_num].predict(X_test_ETC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_pred': [0.8888371226239284, 0.8884644055162132, 0.8894893775624301, 0.8859485650391353, 0.8890234811777861, 0.886134923592993, 0.886600819977637, 0.8919120387625792, 0.8845508758852031, 0.8876257920238539, 0.892005218039508, 0.8877189713007827, 0.8893961982855013, 0.8950801341781588, 0.8903279910547894, 0.8878121505777116, 0.8874394334699963, 0.886134923592993, 0.8700149086843086, 0.8933097279165114, 0.8788669399925456], 'f1_score_pred': [0.882127349247149, 0.8833300110960445, 0.8816206003323926, 0.8749031474414184, 0.8815511988522351, 0.8765957350744161, 0.8815153608349444, 0.8857539151400852, 0.8779174173643959, 0.8801303355250368, 0.8840383153176423, 0.8785973821808549, 0.885055238501806, 0.8895798723014806, 0.8843120605039256, 0.8756139425672571, 0.8801730217330255, 0.8756047499035396, 0.8645198186599062, 0.8864719390510833, 0.8698565430861344], 'recall_score_pred': [0.8888371226239284, 0.8884644055162132, 0.8894893775624301, 0.8859485650391353, 0.8890234811777861, 0.886134923592993, 0.886600819977637, 0.8919120387625792, 0.8845508758852031, 0.8876257920238539, 0.892005218039508, 0.8877189713007827, 0.8893961982855013, 0.8950801341781588, 0.8903279910547894, 0.8878121505777116, 0.8874394334699963, 0.886134923592993, 0.8700149086843086, 0.8933097279165114, 0.8788669399925456], 'precision_score_pred': [0.8823582419091799, 0.8891981678609262, 0.883868460551083, 0.8818974121696307, 0.8843849499577123, 0.8782981377407235, 0.8845203152009751, 0.886061378692075, 0.8815442401005208, 0.8790196324228234, 0.8850905488326998, 0.8812136713523065, 0.8878755517596889, 0.8923672465144016, 0.885148561747479, 0.8796090927029367, 0.8829539260356287, 0.8752691290391922, 0.8734755318486143, 0.8899643562338226, 0.8752671818576171]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "y_train_ETC_single = np.argmax(y_train_ETC, axis=1)\n",
    "y_test_ETC_single = np.argmax(y_test_ETC, axis=1)\n",
    "accuracy_pred = []\n",
    "recall_score_pred = []\n",
    "f1_score_pred = []\n",
    "classification_report_pred = []\n",
    "precision_score_pred = []\n",
    "for ensemble_num in range(ensemble_size):\n",
    "    accuracy_pred.append(accuracy_score(y_test_ETC_single, pred[ensemble_num].argmax(axis=1)))\n",
    "    f1_score_pred.append(f1_score(y_test_ETC_single, pred[ensemble_num].argmax(axis=1), average=\"weighted\"))\n",
    "    recall_score_pred.append(recall_score(y_test_ETC_single, pred[ensemble_num].argmax(axis=1), average=\"weighted\"))\n",
    "    precision_score_pred.append(precision_score(y_test_ETC_single, pred[ensemble_num].argmax(axis=1), average=\"weighted\", zero_division=0))\n",
    "    # classification_report_pred.append(classification_report(y_test_ETC_single, pred[ensemble_num].argmax(axis=1), zero_division=1))\n",
    "\n",
    "eval_metrics_ensemble = {\"accuracy_pred\": accuracy_pred, \n",
    "                         \"f1_score_pred\": f1_score_pred,\n",
    "                         \"recall_score_pred\": recall_score_pred, \n",
    "                         \"precision_score_pred\": precision_score_pred}\n",
    "print(eval_metrics_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of trains and tests on weak model #1\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "prediction of trains and tests on weak model #2\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "prediction of trains and tests on weak model #3\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n",
      "prediction of trains and tests on weak model #4\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "prediction of trains and tests on weak model #5\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "prediction of trains and tests on weak model #6\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n",
      "prediction of trains and tests on weak model #7\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "prediction of trains and tests on weak model #8\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "prediction of trains and tests on weak model #9\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
      "prediction of trains and tests on weak model #10\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "prediction of trains and tests on weak model #11\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "prediction of trains and tests on weak model #12\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
      "prediction of trains and tests on weak model #13\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "prediction of trains and tests on weak model #14\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "prediction of trains and tests on weak model #15\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step\n",
      "prediction of trains and tests on weak model #16\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
      "prediction of trains and tests on weak model #17\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "prediction of trains and tests on weak model #18\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step\n",
      "prediction of trains and tests on weak model #19\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step\n",
      "prediction of trains and tests on weak model #20\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "prediction of trains and tests on weak model #21\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step\n",
      "\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_4980\\3889078255.py:14: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  X_meta_train = np.hstack((weak_model for weak_model in preds_train))\n",
      "C:\\Users\\Pc\\AppData\\Local\\Temp\\ipykernel_4980\\3889078255.py:17: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  X_meta_test = np.hstack((weak_model for weak_model in preds_test))\n"
     ]
    }
   ],
   "source": [
    "preds_train = []\n",
    "preds_test = []\n",
    "ensemble_num = 0\n",
    "\n",
    "for weak_model in ensemble_models:\n",
    "    ensemble_num+=1\n",
    "    print(f\"prediction of trains and tests on weak model #{ensemble_num}\")\n",
    "    # Get the predicted probabilities for each model on the training set\n",
    "    preds_train.append(weak_model.predict(X_train_ETC))\n",
    "    # Get the predicted probabilities for each model on the test set\n",
    "    preds_test.append(weak_model.predict(X_test_ETC))\n",
    "\n",
    "# Stack the training predictions horizontally to create the meta-features\n",
    "X_meta_train = np.hstack((weak_model for weak_model in preds_train))\n",
    "\n",
    "# Stack the test predictions horizontally to create the meta-features\n",
    "X_meta_test = np.hstack((weak_model for weak_model in preds_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting meta estimator LogisticRegression() on meta trains:\n",
      "fitting meta estimator AdaBoostClassifier(random_state=313) on meta trains:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting meta estimator XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...) on meta trains:\n",
      "fitting meta estimator RandomForestClassifier(criterion='entropy') on meta trains:\n",
      "fitting meta estimator KNeighborsClassifier(n_neighbors=6) on meta trains:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the meta-estimator\n",
    "meta_estimator_LR = LogisticRegression()\n",
    "meta_estimator_ABC = AdaBoostClassifier(random_state=313)\n",
    "meta_estimator_XGB = XGBClassifier()\n",
    "meta_estimator_RFC = RandomForestClassifier(criterion=\"entropy\")\n",
    "meta_estimator_KNN = KNeighborsClassifier(n_neighbors=6) #n_neighbors=6: 1/3 the least class support, due to crowd voting theorem\n",
    "\n",
    "meta_estimators = [meta_estimator_LR, meta_estimator_ABC, meta_estimator_XGB, \n",
    "                   meta_estimator_RFC, meta_estimator_KNN]\n",
    "\n",
    "# Train the meta-estimator on the stacked dataset\n",
    "for meta_estimator in meta_estimators:\n",
    "    print(f\"fitting meta estimator {meta_estimator} on meta trains:\")\n",
    "    meta_estimator.fit(X_meta_train, y_train_ETC_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting using meta estimator LogisticRegression() on meta tests:\n",
      "predicting using meta estimator AdaBoostClassifier(random_state=313) on meta tests:\n",
      "predicting using meta estimator XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...) on meta tests:\n",
      "predicting using meta estimator RandomForestClassifier(criterion='entropy') on meta tests:\n",
      "predicting using meta estimator KNeighborsClassifier(n_neighbors=6) on meta tests:\n",
      "Ensemble Model Accuracy for meta_estimator_LR: 0.8957323891166604\n",
      "Ensemble Model Accuracy for meta_estimator_ABC: 0.8369362653745807\n",
      "Ensemble Model Accuracy for meta_estimator_XGB: 0.9036526276556094\n",
      "Ensemble Model Accuracy for meta_estimator_RFC: 0.9058889303019009\n",
      "Ensemble Model Accuracy for meta_estimator_KNN: 0.8956392098397317\n",
      "Classification Report for the meta_estimator_LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      1416\n",
      "           1       0.78      0.39      0.52        46\n",
      "           2       0.60      0.12      0.19        26\n",
      "           3       0.95      0.97      0.96      4865\n",
      "           4       0.64      0.51      0.56        69\n",
      "           5       0.44      0.55      0.49        20\n",
      "           6       0.16      0.13      0.14        69\n",
      "           7       0.49      0.29      0.36        62\n",
      "           8       0.66      0.85      0.74       186\n",
      "           9       0.94      0.94      0.94      2920\n",
      "          10       0.85      0.74      0.80        94\n",
      "          11       0.70      0.15      0.25        46\n",
      "          12       0.86      0.76      0.81       106\n",
      "          13       0.71      0.81      0.75       407\n",
      "          14       0.58      0.46      0.51       400\n",
      "\n",
      "    accuracy                           0.90     10732\n",
      "   macro avg       0.68      0.57      0.59     10732\n",
      "weighted avg       0.89      0.90      0.89     10732\n",
      "\n",
      "Classification Report for the meta_estimator_ABC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86      1416\n",
      "           1       0.54      0.59      0.56        46\n",
      "           2       0.00      0.00      0.00        26\n",
      "           3       0.96      0.95      0.95      4865\n",
      "           4       0.30      0.41      0.35        69\n",
      "           5       0.59      0.50      0.54        20\n",
      "           6       0.00      0.00      0.00        69\n",
      "           7       0.34      0.32      0.33        62\n",
      "           8       0.76      0.70      0.73       186\n",
      "           9       0.72      0.96      0.82      2920\n",
      "          10       0.85      0.72      0.78        94\n",
      "          11       0.23      0.57      0.33        46\n",
      "          12       0.89      0.78      0.83       106\n",
      "          13       0.24      0.03      0.05       407\n",
      "          14       0.07      0.00      0.00       400\n",
      "\n",
      "    accuracy                           0.84     10732\n",
      "   macro avg       0.49      0.49      0.48     10732\n",
      "weighted avg       0.80      0.84      0.81     10732\n",
      "\n",
      "Classification Report for the meta_estimator_XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1416\n",
      "           1       0.71      0.63      0.67        46\n",
      "           2       0.83      0.73      0.78        26\n",
      "           3       0.96      0.97      0.97      4865\n",
      "           4       0.60      0.51      0.55        69\n",
      "           5       0.60      0.60      0.60        20\n",
      "           6       0.22      0.20      0.21        69\n",
      "           7       0.46      0.29      0.36        62\n",
      "           8       0.70      0.87      0.77       186\n",
      "           9       0.94      0.95      0.94      2920\n",
      "          10       0.87      0.78      0.82        94\n",
      "          11       0.76      0.61      0.67        46\n",
      "          12       0.80      0.78      0.79       106\n",
      "          13       0.71      0.80      0.76       407\n",
      "          14       0.60      0.47      0.52       400\n",
      "\n",
      "    accuracy                           0.90     10732\n",
      "   macro avg       0.71      0.67      0.68     10732\n",
      "weighted avg       0.90      0.90      0.90     10732\n",
      "\n",
      "Classification Report for the meta_estimator_RFC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1416\n",
      "           1       0.77      0.52      0.62        46\n",
      "           2       0.79      0.73      0.76        26\n",
      "           3       0.96      0.97      0.97      4865\n",
      "           4       0.65      0.52      0.58        69\n",
      "           5       0.63      0.60      0.62        20\n",
      "           6       0.21      0.13      0.16        69\n",
      "           7       0.53      0.26      0.35        62\n",
      "           8       0.70      0.88      0.78       186\n",
      "           9       0.94      0.95      0.94      2920\n",
      "          10       0.88      0.76      0.81        94\n",
      "          11       0.82      0.61      0.70        46\n",
      "          12       0.84      0.79      0.82       106\n",
      "          13       0.72      0.79      0.75       407\n",
      "          14       0.60      0.47      0.53       400\n",
      "\n",
      "    accuracy                           0.91     10732\n",
      "   macro avg       0.73      0.66      0.68     10732\n",
      "weighted avg       0.90      0.91      0.90     10732\n",
      "\n",
      "Classification Report for the meta_estimator_KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      1416\n",
      "           1       0.84      0.46      0.59        46\n",
      "           2       0.70      0.73      0.72        26\n",
      "           3       0.95      0.97      0.96      4865\n",
      "           4       0.58      0.58      0.58        69\n",
      "           5       0.59      0.50      0.54        20\n",
      "           6       0.19      0.12      0.14        69\n",
      "           7       0.60      0.24      0.34        62\n",
      "           8       0.68      0.83      0.75       186\n",
      "           9       0.94      0.94      0.94      2920\n",
      "          10       0.80      0.72      0.76        94\n",
      "          11       0.65      0.52      0.58        46\n",
      "          12       0.87      0.70      0.77       106\n",
      "          13       0.78      0.53      0.63       407\n",
      "          14       0.53      0.61      0.57       400\n",
      "\n",
      "    accuracy                           0.90     10732\n",
      "   macro avg       0.70      0.62      0.65     10732\n",
      "weighted avg       0.89      0.90      0.89     10732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict on the stacked test set\n",
    "meta_predictions = []\n",
    "for meta_estimator in meta_estimators:\n",
    "    print(f\"predicting using meta estimator {meta_estimator} on meta tests:\")\n",
    "    meta_predictions.append(meta_estimator.predict(X_meta_test))\n",
    "\n",
    "meta_estimators_names = [\"meta_estimator_LR\", \"meta_estimator_ABC\", \"meta_estimator_XGB\", \n",
    "                   \"meta_estimator_RFC\", \"meta_estimator_KNN\"]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracies = []\n",
    "for i in range(len(meta_predictions)):\n",
    "    accuracies.append(accuracy_score(y_test_ETC_single, meta_predictions[i]))\n",
    "    print(f'Ensemble Model Accuracy for {meta_estimators_names[i]}: {accuracies[i]}')\n",
    "\n",
    "# Confusion Matrix\n",
    "# conf_matrix = confusion_matrix(y_test_ETC_single, meta_predictions)\n",
    "# print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification Report\n",
    "class_reports = []\n",
    "for i in range(len(meta_predictions)):\n",
    "    class_reports.append(classification_report(y_test_ETC_single, meta_predictions[i]))\n",
    "    print(f'Classification Report for the {meta_estimators_names[i]}:\\n{class_reports[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting: Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta_train = np.hstack((i for i in pred))\n",
    "X_meta_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting: Soft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
